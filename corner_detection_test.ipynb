{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module\n",
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imagePath = 'C:\\\\Users\\\\Salil kulkarni\\\\Desktop\\\\TARQ\\\\ParkingApp\\\\Images'\n",
    "imageName = \"map3\"\n",
    "resizedImageName = imageName + \"_resized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedPoints = []\n",
    "def click_event_selectedpoints(event, x, y, flags, params):\n",
    "\n",
    "# checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selectedPoints.append([x,y])\n",
    "\n",
    "def get_resized_for_display_img(img):\n",
    "    screen_w, screen_h = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "    #print(\"screen size\",screen_w, screen_h)\n",
    "    h,w,channel_nbr = img.shape\n",
    "    # img get w of screen and adapt h\n",
    "    h = h * (screen_w / w)\n",
    "    w = screen_w\n",
    "    if h > screen_h: #if img h still too big\n",
    "        # img get h of screen and adapt w\n",
    "        w = w * (screen_h / h)\n",
    "        h = screen_h\n",
    "    w, h = w*0.9, h*0.9 # because you don't want it to be that big, right ?\n",
    "    w, h = int(w), int(h) # you need int for the cv2.resize\n",
    "    return cv2.resize(img, (w, h))\n",
    "\n",
    "def get_MP_FromBuildings_ButAlsoText(img):\n",
    "\n",
    "    # Upper and lower color limit\n",
    "    low_yellow = (239,248,253)\n",
    "    high_yellow = (243,252,255)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    yellow_mask = cv2.inRange(img, low_yellow, high_yellow )\n",
    "    gray_mask = cv2.inRange(img, low_gray, high_gray)\n",
    "\n",
    "    # combine masks\n",
    "    combined_mask = cv2.bitwise_or(yellow_mask, gray_mask)\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    output = img.copy()\n",
    "\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 500:\n",
    "            for eps in np.linspace(0.001, 0.005, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(output, [approx], -1, (0, 255, 0), thickness=1)\n",
    "            # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "\n",
    "\n",
    "    # write points in mounting list\n",
    "    mountingPoints = []\n",
    "    for y in range(len(img)):\n",
    "        for x in range(len(img[y])):\n",
    "            b = img[y, x, 0]\n",
    "            g = img[y, x, 1]\n",
    "            r = img[y, x, 2]\n",
    "            if(b == 255 and g == 0 and r == 255):\n",
    "                mountingPoints.append((x,y))\n",
    "\n",
    "    # return mountingPoints\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the resized the image\n",
    "img = cv2.imread(os.path.join(imagePath, resizedImageName+\".PNG\"), 1)\n",
    "\n",
    "image = img.copy()\n",
    "# convert image to HSV\n",
    "#hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#will show black and white image of borders of the buildings. Click on this image at different points to encircle a \n",
    "#a structure for corner detection. Coordinates will not be displayed. Coordinates will be stored and resultant mask will\n",
    "#be displayed.\n",
    "cntr_img = get_MP_FromBuildings_ButAlsoText(img)\n",
    "\n",
    "cv2.imshow(\"cntr trace\", cntr_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('cntr trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper and lower color limit\n",
    "low_yellow = (239,248,253)\n",
    "high_yellow = (243,252,255)\n",
    "\n",
    "low_gray = (241,241,241)\n",
    "high_gray = (244,243,241)\n",
    "\n",
    "# create masks\n",
    "yellow_mask = cv2.inRange(img, low_yellow, high_yellow )\n",
    "gray_mask = cv2.inRange(img, low_gray, high_gray)\n",
    "\n",
    "# combine masks\n",
    "combined_mask = cv2.bitwise_or(yellow_mask, gray_mask)\n",
    "kernel = np.ones((3,3), dtype=np.uint8)\n",
    "combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "#     # combine masks\n",
    "\n",
    "original_frame = cv2.imread(os.path.join(imagePath, resizedImageName+\".PNG\"), 1)\n",
    "# original_frame = get_resized_for_display_img(original_frame)\n",
    "points = np.array(selectedPoints)\n",
    "blank = np.zeros(original_frame.shape[:2], dtype='uint8')\n",
    "poly_pts = np.array(points, dtype='uint32')\n",
    "poly_pts = poly_pts.reshape((-1, 1, 2))\n",
    "polymask = cv2.fillPoly(blank, pts=poly_pts,color=255)\n",
    "masked = cv2.bitwise_and(original_frame,original_frame,mask=polymask)\n",
    "masked = cv2.bitwise_and(masked,masked,mask=combined_mask)\n",
    "\n",
    "\n",
    "#will display masked quadrilateral whose points were selected prior\n",
    "cv2.imshow(\"out\", masked)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "operatedImage = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# modify the data type\n",
    "# setting to 32-bit floating point\n",
    "# operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "operatedImage = np.float32(operatedImage)\n",
    "\n",
    "# apply the cv2.cornerHarris method\n",
    "# to detect the corners with appropriate\n",
    "# values as input parameters\n",
    "dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "# Results are marked through the dilated corners\n",
    "dest = cv2.dilate(dest, None)\n",
    "\n",
    "# Reverting back to the original image,\n",
    "# with optimal threshold value\n",
    "original_frame[dest > 0.01 * dest.max()]=[0, 255, 0]\n",
    "\n",
    "# the window showing output image with corners\n",
    "cv2.imshow('Image with Borders', original_frame)\n",
    "\n",
    "#     # De-allocate any associated memory usage\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorner(image):\n",
    "\n",
    "    # making a copy of the image to have the original image untouched in main loop\n",
    "    imageSub = image.copy()\n",
    "    original_frame = image.copy()\n",
    "\n",
    "    # convet to gray and perform Harris corner detection\n",
    "    gray = cv2.cvtColor(imageSub,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    og = cv2.cvtColor(original_frame,cv2.COLOR_BGR2GRAY)\n",
    "    og = np.float32(og)\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "    dest = cv2.cornerHarris(og, 2, 5, 0.07)\n",
    "\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # threshold for an optimal value, it may vary depending on the image.\n",
    "    imageSub[dst>0.01*dst.max()]=[0,0,255]\n",
    "    # og[dest > 0.01 * dest.max()]=[0, 0, 255]\n",
    "\n",
    "    imageSub = og-imageSub\n",
    "\n",
    "    return imageSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (617,1382) (617,1382,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Salil kulkarni\\Desktop\\TARQ\\ParkingApp\\corner_detection_test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# reading the resized the image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(imagePath, resizedImageName\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.PNG\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cntr_img \u001b[39m=\u001b[39m detectCorner(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mcntr trace\u001b[39m\u001b[39m\"\u001b[39m, cntr_img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Salil kulkarni\\Desktop\\TARQ\\ParkingApp\\corner_detection_test.ipynb Cell 8\u001b[0m in \u001b[0;36mdetectCorner\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m imageSub[dst\u001b[39m>\u001b[39m\u001b[39m0.01\u001b[39m\u001b[39m*\u001b[39mdst\u001b[39m.\u001b[39mmax()]\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# og[dest > 0.01 * dest.max()]=[0, 0, 255]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m imageSub \u001b[39m=\u001b[39m og\u001b[39m-\u001b[39;49mimageSub\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/ParkingApp/corner_detection_test.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m imageSub\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (617,1382) (617,1382,3) "
     ]
    }
   ],
   "source": [
    "# reading the resized the image\n",
    "img = cv2.imread(os.path.join(imagePath, resizedImageName+\".PNG\"), 1)\n",
    "\n",
    "cntr_img = detectCorner(img)\n",
    "\n",
    "cv2.imshow(\"cntr trace\", cntr_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('cntr trace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
