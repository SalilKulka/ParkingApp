{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all modules\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a class to store x and y coordinates of points\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def toList(self):\n",
    "        return [self.x, self.y]\n",
    "\n",
    "# Make a class to store the view covered by a camera at each position  \n",
    "class camView:\n",
    "    def __init__(self, point0, point1, point2, area, cameraRoadCoverage):\n",
    "        self.p0 = point0\n",
    "        self.p1 = point1\n",
    "        self.p2 = point2\n",
    "        self.area = area\n",
    "        self.cameraRoadCoverage = cameraRoadCoverage\n",
    "\n",
    "    def getNpPts(self):\n",
    "        return np.array([self.p0.toList(), self.p1.toList(), self.p2.toList()], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b):\n",
    "    return math.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n",
    "\n",
    "def is_between(a,c,b):\n",
    "    softCheck = distance(a,c) + distance(c,b) - distance(a,b)\n",
    "    return abs(softCheck) <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFarthestPoint(p1, ptList):\n",
    "    #returns either of p2 or p3 depending on which point is farthest away from p1 (mounting point)\n",
    "    p = (0, 0)\n",
    "\n",
    "    # Calculating distances\n",
    "    d1 = abs(math.sqrt(math.pow(p1[0]-ptList[0][0],2)+math.pow(p1[1]-ptList[0][1],2)))\n",
    "    d2 = abs(math.sqrt(math.pow(p1[0]-ptList[1][0],2)+math.pow(p1[1]-ptList[1][1],2)))\n",
    "\n",
    "    # Compare distances\n",
    "    if d1 > d2:\n",
    "        p = ptList[0]\n",
    "    else:\n",
    "        p[1] = ptList[1]\n",
    "\n",
    "    # Return point\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMountingPoints(img):\n",
    "\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(imageCopy, low_red, low_red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "\n",
    "    # setting to 32-bit floating point\n",
    "    operatedImage = np.float32(combined_mask)\n",
    "\n",
    "    # apply the cv2.cornerHarris method to detect the corners with appropriate values as input parameters\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 3, 0.04)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # draw on the output image\n",
    "    imageCopy[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    return imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the corners into one point\n",
    "def cluster2Point(clusterImg):\n",
    "\n",
    "    # Innitate the the single point corner arrays\n",
    "    Points = []\n",
    "\n",
    "    # Create masks for the corner clusters\n",
    "    if(len(clusterImg.shape)==2):\n",
    "        white_mask = cv2.inRange(clusterImg, 255, 255)\n",
    "    elif(len(clusterImg.shape)==3):\n",
    "        white_mask = cv2.inRange(clusterImg, (255,255,255), (255,255,255))\n",
    "\n",
    "    # Combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # Approximate the clusters to a single point/pixel\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "\n",
    "        Points.append([cx,cy])\n",
    "\n",
    "    # Return a list of points \n",
    "    return Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoadsnParkings(img):\n",
    "  \n",
    "    # define color ranges\n",
    "    # blue_lower = (250,0,0)\n",
    "    blue = np.array([255, 0, 0], dtype=\"uint8\")\n",
    "\n",
    "    # create mask\n",
    "    blue_mask = cv2.inRange(img, blue, blue)\n",
    "\n",
    "    return blue_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointGen(source, m, l):\n",
    "    \n",
    "    # m is the slope of line, and the required Point lies distance l away from the source Point\n",
    "    a = Point(0, 0)\n",
    "    b = Point(0, 0)\n",
    "\n",
    "    # slope is 0\n",
    "    if m == 0:\n",
    "        a.x = source.x + l\n",
    "        a.y = source.y\n",
    "\n",
    "        b.x = source.x - l\n",
    "        b.y = source.y\n",
    "\n",
    "    # if slope is infinite\n",
    "    elif math.isfinite(m) is False:\n",
    "        a.x = source.x\n",
    "        a.y = source.y + l\n",
    "\n",
    "        b.x = source.x\n",
    "        b.y = source.y - l\n",
    "    else:\n",
    "        dx = (l / math.sqrt(1 + (m * m)))\n",
    "        dy = m * dx\n",
    "        a.x = source.x + dx\n",
    "        a.y = source.y + dy\n",
    "        b.x = source.x - dx\n",
    "        b.y = source.y - dy\n",
    "    \n",
    "    return [[a.x,a.y],[b.x,b.y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorner(image):\n",
    "\n",
    "    # making a copy of the image to have the original image untouched in main loop\n",
    "    imageSub = image.copy()\n",
    "\n",
    "    # convert to gray and perform Harris corner detection\n",
    "    gray = cv2.cvtColor(imageSub,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    \n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining mounting points from red buildings img\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "\n",
    "    # threshold for an optimal value, it may vary depending on the image.\n",
    "    imageSub[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "    return imageSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs only once using new bgr values for the new image in low red.\n",
    "def getBorderContour(img):\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, red, red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "  \n",
    "    return blank, combined_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(mountingPt, pointsCoords, y_lim, x_lim):\n",
    "\n",
    "    #draws line segment infinitely from edges of image\n",
    "    # x1,y1,x2,y2 = points2[0]\n",
    "\n",
    "    p = [-1, -1]\n",
    "    q = [-1, -1]\n",
    "\n",
    "    if mountingPt[0]==pointsCoords[0]:\n",
    "\n",
    "        p[0] = pointsCoords[0]\n",
    "        p[1] = y_lim\n",
    "\n",
    "        if not is_between(mountingPt, [pointsCoords[0],pointsCoords[1]], p):\n",
    "            p[0] = pointsCoords[0]\n",
    "            p[1] = 0\n",
    "\n",
    "    else:\n",
    "        slope1 = (mountingPt[1] - pointsCoords[1])/(mountingPt[0] - pointsCoords[0])\n",
    "\n",
    "        p[0] = x_lim\n",
    "        p[1] = slope1*x_lim + (pointsCoords[1] - slope1*pointsCoords[0])\n",
    "\n",
    "        if not is_between(mountingPt, [pointsCoords[0],pointsCoords[1]], p):\n",
    "            p[0] = 0\n",
    "            p[1] = (pointsCoords[1] - slope1*pointsCoords[0])\n",
    "\n",
    "    #__________________________________________________________________________________#\n",
    "\n",
    "    if mountingPt[0]==pointsCoords[2]:\n",
    "\n",
    "        q[0] = pointsCoords[2]\n",
    "        q[1] = y_lim\n",
    "\n",
    "        if not is_between(mountingPt, [pointsCoords[2],pointsCoords[3]], q):\n",
    "            q[0] = pointsCoords[2]\n",
    "            q[1] = 0\n",
    "\n",
    "    else:\n",
    "        slope2 = (mountingPt[1] - pointsCoords[3])/(mountingPt[0] - pointsCoords[2])\n",
    "\n",
    "        q[0] = x_lim\n",
    "        q[1] = slope2*x_lim + (pointsCoords[3] - slope2*pointsCoords[2])\n",
    "\n",
    "        if not is_between(mountingPt, [pointsCoords[2],pointsCoords[3]], q):\n",
    "            q[0] = 0\n",
    "            q[1] = (pointsCoords[3] - slope2*pointsCoords[2])\n",
    "\n",
    "    \n",
    "\n",
    "    return p, q  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoadCoverageMask(selected_edge_list, mountingPoint, yLim, xLim, img):\n",
    "\n",
    "    # Initiate mask \n",
    "    totalMask = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "    # Looping through all the edges of buildings inside camera coverage to perform manual ray traced image\n",
    "    for selected_edge_contour in selected_edge_list:\n",
    "\n",
    "        # Mask related to a single contour, to which individual line blocking masks will be OR'ed to \n",
    "        oneContourPic = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "        # Draws only selected contour for the loop\n",
    "        cv2.drawContours(oneContourPic, [selected_edge_contour], -1, 255, thickness=1) \n",
    "        oneContourPic = cv2.Canny(oneContourPic,50,150,apertureSize=3)\n",
    "        \n",
    "\n",
    "        # Apply HoughLinesP method to directly obtain line end points\n",
    "        lines = cv2.HoughLinesP(\n",
    "                    oneContourPic, # Input edge image\n",
    "                    1, # Distance resolution in pixels\n",
    "                    np.pi/180, # Angle resolution in radians\n",
    "                    threshold=11, # Min number of votes for valid line. Use lesser number of votes for smaller lines\n",
    "                    minLineLength=5, # Min allowed length of line\n",
    "                    maxLineGap=10 # Max allowed gap between line for joining them\n",
    "                    )\n",
    "\n",
    "        #same line is appearing in the pic twice, perhaps increase threshold (number of votes/points)\n",
    "        if(lines is None):\n",
    "            continue\n",
    "\n",
    "        # Loop through the edges of buildings for fake ray traced image\n",
    "        for points in lines:\n",
    "\n",
    "            # Parse the points of the lines\n",
    "            interiorPointCoords_1 = (points[0][0], points[0][1])\n",
    "            interiorPointCoords_2 = (points[0][2], points[0][3])\n",
    "\n",
    "            # Obtaining the point colinear with mounting point and building edge on the edge of the image\n",
    "            brdrPoint_1, brdrPoint_2 = drawLine(mountingPoint, points[0], yLim, xLim)\n",
    "\n",
    "            # Select the points of the poygon to exclude everything behind a building edge blocking the camera\n",
    "            if (brdrPoint_1[0]==0 and brdrPoint_2[1]==0) or (brdrPoint_1[1]==0 and brdrPoint_2[0]==0):\n",
    "                exPoints = [interiorPointCoords_1, brdrPoint_1, [0,0], brdrPoint_2, interiorPointCoords_2]\n",
    "            elif (brdrPoint_1[0]==xLim and brdrPoint_2[1]==0) or (brdrPoint_1[1]==0 and brdrPoint_2[0]==xLim):\n",
    "                exPoints = [interiorPointCoords_1, brdrPoint_1, [xLim,0], brdrPoint_2, interiorPointCoords_2]\n",
    "            elif (brdrPoint_1[0]==0 and brdrPoint_2[1]==yLim) or (brdrPoint_1[1]==yLim and brdrPoint_2[0]==0):\n",
    "                exPoints = [interiorPointCoords_1, brdrPoint_1, [0,yLim], brdrPoint_2, interiorPointCoords_2]\n",
    "            elif (brdrPoint_1[0]==xLim and brdrPoint_2[1]==yLim) or (brdrPoint_1[1]==yLim and brdrPoint_2[0]==xLim):\n",
    "                exPoints = [interiorPointCoords_1, brdrPoint_1, [xLim,yLim], brdrPoint_2, interiorPointCoords_2]\n",
    "            else:\n",
    "                exPoints = [interiorPointCoords_1, brdrPoint_1, brdrPoint_2, interiorPointCoords_2]\n",
    "            \n",
    "            \n",
    "            # fill poly for excluded region\n",
    "            exPoints = np.array(exPoints, dtype=np.int32)\n",
    "            blockPts = exPoints.reshape((-1, 1, 2))\n",
    "            totalMask = cv2.fillPoly(totalMask, pts=[blockPts],color=255)\n",
    "\n",
    "    # Get the included region from the excluded region\n",
    "    totalMask = cv2.bitwise_not(totalMask)\n",
    "\n",
    "    return totalMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genQuadImages(pt):\n",
    "    cutQuadMask3D = np.zeros(img.shape, dtype='uint8')\n",
    "    cutQuadMask2D = np.zeros(img.shape[:2], dtype='uint8')\n",
    "    cutQuadBorder = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "    pt = pt.reshape((-1,1,2))\n",
    "    \n",
    "    cv2.fillPoly(cutQuadMask3D, [pt], (255,255,255))\n",
    "    cv2.fillPoly(cutQuadMask2D, [pt], 255)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(cutQuadMask2D, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        for eps in np.linspace(0.001, 0.01, 10):\n",
    "            # approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "        \n",
    "        # draw the approximated contour on the image  \n",
    "        cv2.drawContours(cutQuadBorder, approx, -1, 255, thickness=1)\n",
    "    return cutQuadMask3D, cutQuadBorder, cutQuadMask2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMountingPoints(img, road, mountingPointsList, ALPHA, bldg_mask, bldg_brdr_gray):\n",
    "    retList = []\n",
    "    for mountingPoint in mountingPointsList:\n",
    "        for beta in range (0,360,10):\n",
    "            BETA = (beta*math.pi)/180\n",
    "            if(beta==180 or beta==0 or beta==360):\n",
    "                continue\n",
    "            further_dist = heightPix[20]*math.tan(ALPHA + (phi/2))\n",
    "\n",
    "            # slope of horizontal plane camera angle\n",
    "            slope_beta = math.tan(BETA)\n",
    "\n",
    "            # midpoints of closer and further edges\n",
    "            if beta > 180:\n",
    "                further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[1]\n",
    "            else:\n",
    "                further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[0]\n",
    "\n",
    "            further_edge =(heightPix[20]*math.tan(omega/2))/math.cos(ALPHA+(phi/2))\n",
    "\n",
    "            # Obtaining on ground triangle points\n",
    "            point1 = [mountingPoint[0],mountingPoint[1]]\n",
    "            point2 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[1]\n",
    "            point3 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[0]\n",
    "            \n",
    "            # plotting the points\n",
    "            pt = np.array([point1, point2, point3], np.int32)\n",
    "            _, _, CameraCoverage2 = genQuadImages(pt)\n",
    "\n",
    "            circleCheck = np.zeros(img.shape[:2], dtype = \"uint8\")\n",
    "            cv2.circle(circleCheck, (mountingPoint[0], mountingPoint[1]), 3, 255, 1)\n",
    "            Check_step1 = cv2.bitwise_and(circleCheck, CameraCoverage2)\n",
    "            Check_step2 = cv2.bitwise_and(Check_step1, bldg_mask)\n",
    "            nonzeroX, _ = np.nonzero(Check_step2)\n",
    "            if len(nonzeroX)==0:\n",
    "                pt = np.array([point1, point2, point3], np.int32)\n",
    "\n",
    "                # get building borders inside viewing quadrilateral\n",
    "                selected_bldg_brdrs_gray = cv2.bitwise_and(bldg_brdr_gray,CameraCoverage2) # Gray\n",
    "\n",
    "                \n",
    "                # \n",
    "                selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "                \n",
    "                roadCoveredMask = getRoadCoverageMask(selected_edge_list, mountingPoint, yLim, xLim, img)\n",
    "\n",
    "                cameraRoadCoverage = cv2.bitwise_and(road, CameraCoverage2, mask = roadCoveredMask)\n",
    "\n",
    "                retList.append(camView(Point(mountingPoint[0], mountingPoint[1]),Point(point2[0], point2[1]),Point(point3[0], point3[1]), 0, cameraRoadCoverage))\n",
    "\n",
    "        # retList.sort(key=lambda n: n.area, reverse=True)\n",
    "    return retList\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(img, camViewList, road):\n",
    "\n",
    "    maxArea = 0\n",
    "    imgCopy = img.copy()\n",
    "    index = 0\n",
    "    \n",
    "    for view in camViewList:\n",
    "            \n",
    "        # Getting the camera coverage area\n",
    "        cameraRoadCoverage, _, CameraCoverage2 = genQuadImages(view.getNpPts())\n",
    "        cameraRoadCoverage = cv2.bitwise_and(road, CameraCoverage2, mask = view.cameraRoadCoverage)\n",
    "        \n",
    "        # find the updated are of camera coverage\n",
    "        area_sum = np.count_nonzero(cameraRoadCoverage)\n",
    "\n",
    "        if area_sum > maxArea:\n",
    "            maxArea = area_sum\n",
    "            fp2 = view.p1\n",
    "            fp3 = view.p2\n",
    "            mp = view.p0\n",
    "            excludedRoad = cameraRoadCoverage\n",
    "            maxCameraRoadCoverage = cv2.bitwise_or(cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY), cameraRoadCoverage)\n",
    "            index = camViewList.index(view)\n",
    "\n",
    "    \n",
    "    return camView(mp, fp2, fp3,0,None), excludedRoad, maxCameraRoadCoverage, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imagePath = \"Images\\DubaiImg.png\"\n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "yLim, xLim = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaSelection = img.copy()\n",
    "\n",
    "priorityAreas = []\n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "# mouse callback function\n",
    "def selectArea(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode,preDrawState\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "        preDrawState = areaSelection.copy()\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        preDrawState = areaSelection.copy()\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv2.rectangle(preDrawState,(ix,iy),(x,y),(0,255,0), 1)\n",
    "            else:\n",
    "                cv2.circle(preDrawState,(x,y),5,(0,0,255),-1)\n",
    "        cv2.imshow(\"Priority Selection\", preDrawState)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv2.rectangle(areaSelection,(ix,iy),(x,y),(0,255,0),1)\n",
    "        else:\n",
    "            cv2.circle(areaSelection,(x,y),5,(0,0,255),-1)\n",
    "        priorityAreas.append(((ix,iy),(x,y)))\n",
    "        cv2.imshow(\"Priority Selection\", areaSelection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalePoints = [(302, 373), (464, 373)] # points obtained from sample_scale.PNG map which is a google maps with the same dimensions\n",
    "mountingPoints = []\n",
    "\n",
    "theta = (66.75*math.pi)/180    #diagonal angle FOV of camera (GIVEN!!)\n",
    "phi = 2*math.atan(0.8*math.tan(theta/2))  #angle of view larger side of camera resolution (4 in 4:3)\n",
    "omega = 2*math.atan(0.6*math.tan(theta/2))     #angle of view larger side of camera resolution (3 in 4:3)\n",
    "alpha = (75*math.pi)/180   #set later on in the code based on the height of the camera [angle of camera from negative z axis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale for pix to meter conversion\n",
    "scaleConst = 20 \n",
    "\n",
    "# Pixel distance of scale in image\n",
    "# actual distance(m) = (scale constant)*(obtained magnitude)/scale\n",
    "scale = abs(math.sqrt(pow(scalePoints[0][0] - scalePoints[1][0],2) + pow(scalePoints[0][1] - scalePoints[1][1],2)))\n",
    "\n",
    "# heights = [x*0.1 for x in range(30,60)] #average height of light poles is 9 to 14 feet ~ 4.2m max\n",
    "heights = [h*0.1 for h in range(30, 60)]    #3m to 6m\n",
    "# Converting height in meter array to height in pixel array\n",
    "heightPix = [h*scale/scaleConst for h in heights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((380, 103), (487, 212))]\n"
     ]
    }
   ],
   "source": [
    "# reading the resized the image\n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "# obtaining the mask of the roads and parkings in the map image\n",
    "road = getRoadsnParkings(img)   #image is grayscale\n",
    "# Create a quadtree to partition the large area A\n",
    "# tree = Index(bbox=[0, 0, road.shape[1], road.shape[0]])\n",
    "# # Insert each pixel in the large area A into the quadtree\n",
    "# for i in range(road.shape[0]):\n",
    "#     for j in range(road.shape[1]):\n",
    "#         if road[i, j] == 255:\n",
    "#             tree.insert((j, i, j, i))\n",
    "\n",
    "cv2.namedWindow('Priority Selection')\n",
    "cv2.setMouseCallback('Priority Selection',selectArea)\n",
    "\n",
    "cv2.imshow(\"Priority Selection\", areaSelection)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(priorityAreas)\n",
    "\n",
    "priorityMask = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "nonPriorityMask = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "for rect in priorityAreas:\n",
    "    cv2.rectangle(priorityMask,rect[0],rect[1],255, -1)\n",
    "cv2.subtract(road, priorityMask, nonPriorityMask)\n",
    "cv2.bitwise_and(road, priorityMask, priorityMask)\n",
    "cv2.imshow(\"Non Priority Mask\", nonPriorityMask)\n",
    "cv2.imshow(\"Priority Mask\", priorityMask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('win', road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "ALPHA = 40*math.pi/180\n",
    "\n",
    "mountingCluster = getMountingPoints(img)\n",
    "mountingPointsList = cluster2Point(mountingCluster)\n",
    "# mountingObjects = [Point(mountingPointsList[i][0], mountingPointsList[i][1]) for i in range(len(mountingPointsList))]\n",
    "# mountingPoints_Angle_Dict = {mountingObject:[] for mountingObject in mountingObjects}\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"mounting points as pixels\", mountingCluster)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting building borders by using a mask function\n",
    "bldg_brdr, bldg_mask = getBorderContour(img)\n",
    "bldg_brdr_gray = cv2.cvtColor(bldg_brdr, cv2.COLOR_BGR2GRAY)\n",
    "camViewList = processMountingPoints(img, road, mountingPointsList, ALPHA, bldg_mask, bldg_brdr_gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle of camera from negative of vertical axisS\n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "yLim, xLim = img.shape[:2]\n",
    "roadLive = road.copy()\n",
    "\n",
    "selectedViews = []\n",
    "\n",
    "maxCameraRoadCoverage2 = img.copy()\n",
    "\n",
    "maxCameraRoadCoverage = []\n",
    "\n",
    "numCam = 3\n",
    "camPlaced = 0\n",
    "\n",
    "while(len(priorityAreas)):\n",
    "    selectedView, excludedRoad1, maxCameraRoadCoverage_0, delIndex = main(img, camViewList, priorityMask)\n",
    "\n",
    "    selectedViews.append(selectedView)\n",
    "    del camViewList[delIndex]\n",
    "\n",
    "    priorityMask = cv2.bitwise_and(priorityMask, cv2.bitwise_not(excludedRoad1))\n",
    "    roadLive = cv2.bitwise_and(roadLive, cv2.bitwise_not(excludedRoad1))\n",
    "    camPlaced = camPlaced + 1\n",
    "\n",
    "    coverage = np.count_nonzero(priorityMask)\n",
    "\n",
    "    if(camPlaced>=numCam or coverage<10):   #if number of cameras placed is equal to max number of cameras, or all priority \n",
    "        #priority areas have been covered ---> break out of the loop\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "while(camPlaced<numCam):\n",
    "\n",
    "    selectedView, excludedRoad1, maxCameraRoadCoverage_0, delIndex = main(img, camViewList, roadLive)\n",
    "\n",
    "    selectedViews.append(selectedView)\n",
    "    del camViewList[delIndex]\n",
    "\n",
    "    roadLive = cv2.bitwise_and(roadLive, cv2.bitwise_not(excludedRoad1))\n",
    "    camPlaced = camPlaced+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing image\n",
    "for x in range(len(selectedViews)):\n",
    "     mp = selectedViews[x].p0.toList()\n",
    "     fp2 = selectedViews[x].p1.toList()\n",
    "     fp3 = selectedViews[x].p2.toList()\n",
    "     cv2.circle(maxCameraRoadCoverage2, mp, 5, (255,0,0),2)\n",
    "     pts = np.array([mp, fp2, fp3],np.int32)\n",
    "     pts = pts.reshape((-1,1,2))\n",
    "     cv2.polylines(maxCameraRoadCoverage2, [pts], True, (255,255,255))\n",
    "cv2.imshow('included v2 static', maxCameraRoadCoverage2)\n",
    "# cv2.imshow('excluded', GlobalCheck1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# print(mountingPoints_Angle_Dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
