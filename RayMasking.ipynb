{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imagePath = 'Images'\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "\n",
    "mountingPoints = []\n",
    "quadPoints = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to do test/implement ray masking\n",
    "1. Plot out viewing quadrilateral\n",
    "2. Plot out mounting point\n",
    "3. Mask out for building contours\n",
    "4. Find corners of building contours\n",
    "\n",
    "Taking the nearest corner, find the slope of the line joining the mounting point and this nearest corner. Find the intersection point of this line and the farthest edge of the quadrilateral (What if farthest edge is out of bounds ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using new bgr values for the new image in low red.\n",
    "def getBorderContour_text(img):\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "    high_yellow = (242,251,256)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, low_red, low_red )\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.0075, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, 255, thickness=1)\n",
    "            # cv2.drawContours(img, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return blank,masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mountingPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 0, 0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        quadPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y),(x,y), font, 1,(0, 0, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners(masked):\n",
    "\n",
    "    operatedImage = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # modify the data type\n",
    "    # setting to 32-bit floating point\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate\n",
    "    # values as input parameters\n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining corners for ray masking\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # for pts in poly_pts:\n",
    "    #     dest[pts[0]][pts[1]] = 0\n",
    "    # Reverting back to the original image,\n",
    "    # with optimal threshold value\n",
    "    size = masked.shape\n",
    "\n",
    "    quadCorners = np.zeros(size, dtype='uint8')\n",
    "    quadCorners[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    blank = np.zeros(masked.shape[:2], dtype='uint8')\n",
    "    poly_pts = np.array( quadPoints ,dtype=np.int32)\n",
    "    poly_pts = poly_pts.reshape((-1, 1, 2))\n",
    "    polymask = cv2.fillPoly(blank, pts=[poly_pts],color=255)\n",
    "\n",
    "    quadCorners = cv2.bitwise_and(quadCorners,quadCorners,mask=polymask)\n",
    "\n",
    "    counter = 0\n",
    "    # for y in range(len(quadCorners)):\n",
    "    #     for x in range(len(quadCorners[y])):\n",
    "    #         if(quadCorners[y,x,0]==255 and quadCorners[y,x,1]==255 and quadCorners[y,x,2]==255):\n",
    "    #             counter = counter + 1\n",
    "    # print(f\"in house counter = {counter}\")\n",
    "\n",
    "    cv2.imshow(\"quadCorners\",quadCorners)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    #     # De-allocate any associated memory \n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return quadCorners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMountingPoints(img):\n",
    "\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(imageCopy, low_red, low_red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # convert to grayscale\n",
    "    # operatedImage = cv2.cvtColor(combined_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # setting to 32-bit floating point\n",
    "    operatedImage = np.float32(combined_mask)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate values as input parameters\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 3, 0.04)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # draw on the output image\n",
    "    imageCopy[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    return imageCopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the corners into one point\n",
    "def cluster2Point(clusterImg, img):\n",
    "\n",
    "    # innitates the the single point corner arrays\n",
    "    cornerCenters = []\n",
    "\n",
    "    # blank = np.zeros(img.shape, dtype='uint8')\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # create masks for the corner clusters\n",
    "    white_mask = cv2.inRange(clusterImg, (255,255,255), (255,255,255))\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        cornerCenters.append([cx,cy])\n",
    "        cv2.circle(imageCopy, (cx, cy), 1, (255, 255, 255), -1)\n",
    "        # cv2.drawContours(blank, [i], -1, 0, -1)\n",
    "\n",
    "    return cornerCenters, imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "\n",
    "mountingCluster = getMountingPoints(img)\n",
    "mountingpixels, pixelImage = cluster2Point(mountingCluster, img)\n",
    "\n",
    "cv2.imshow(\"mounting points as pixels\",pixelImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.setMouseCallback('img', click_MountingnScale_points)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "bldg_brdrs, bldg_mask = getBorderContour_text(img)\n",
    "cv2.imshow(\"bldng_brdrs\",bldg_brdrs)\n",
    "cv2.imshow(\"bldng_mask\",bldg_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "poly_pts = np.array( quadPoints ,dtype=np.int32)\n",
    "poly_pts = poly_pts.reshape((-1, 1, 2))\n",
    "polymask = cv2.fillPoly(blank, pts=[poly_pts],color=255)\n",
    "\n",
    "highlighted_corners = getCorners(bldg_mask)\n",
    "cornerPoints,point_corners = cluster2Point(highlighted_corners)\n",
    "point_corners = cv2.bitwise_or(bldg_mask, point_corners)\n",
    "point_corners = cv2.bitwise_and(point_corners, point_corners, mask = polymask)\n",
    "cv2.imshow('Image with Point Corners', point_corners)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "counter = 0\n",
    "for y in range(len(highlighted_corners)):\n",
    "    for x in range(len(highlighted_corners[y])):\n",
    "        if(highlighted_corners[y,x,0]==255 and highlighted_corners[y,x,1]==255 and highlighted_corners[y,x,2]==255):\n",
    "            counter = counter + 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mountingPoint = mountingPoints[0]\n",
    "\n",
    "# slope_farthest_edge = (quadPoints[3][1]-quadPoints[2][1])/(quadPoints[3][0]-quadPoints[2][0]) #slope of farthest edge line\n",
    "\n",
    "# c2 = quadPoints[3][1] - slope_farthest_edge*quadPoints[3][0] #constant of farthest edge line\n",
    "\n",
    "# for cornerPoint in cornerPoints:\n",
    "#     #if corner point is already blacked out, do not do operations w/ it\n",
    "#     if(img[cornerPoint[1], cornerPoint[2], 0] == 0 and img[cornerPoint[1], cornerPoint[2], 1] == 0 and img[cornerPoint[1], cornerPoint[2], 2] == 0):\n",
    "#         continue\n",
    "#     slope = (mountingPoint[1] - cornerPoint[1])/(mountingPoint[0] - cornerPoint[0])\n",
    "#     #find the intersection point b/w the farthest edge line and the line joining cornerPoint and mountingPoint\n",
    "#     #points are selected such that quadPoints[3] and quadPoints[4] represent the points for the farthest edge\n",
    "    \n",
    "\n",
    "#     #finding intersection point of both lines associated w/ slope\n",
    "#     #x_intercept = (c2-c1)/(m1-m2)\n",
    "#     #y_intercept = m1*x_intercept + c1\n",
    "\n",
    "#     c1 = mountingPoint[1] - slope*mountingPoint[0] #constant of line joining mounting point and corner = y1 - mx1\n",
    "\n",
    "#     #have obtained one point for the blacked out region\n",
    "#     x_intercept = (c2-c1)/(slope - slope_farthest_edge)\n",
    "#     y_intercept = slope*x_intercept + c1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 2 walls associated w/ each building corner. These can be represented as lines.\n",
    "\n",
    "Run corner detection on the image named point_corners. For every corner found, first check if it has been marked as white. If not, then mark it in a different colour (magenta).\n",
    "\n",
    "Once done, for each white corner, check which 2 magenta corners are the closest to it. Joining white corners to their associated white points forms the walls of the bldg.\n",
    "\n",
    "For each of these two lines, use the line closest to the mounting point as the border of darkened polygon - joined to the nearest edge of the viewing quadrilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_corners = getCorners(point_corners)\n",
    "total_corners,point_corners = cluster2Point(point_corners)\n",
    "\n",
    "\n",
    "\n",
    "for cornerPoint in cornerPoints:\n",
    "    point_corners[cornerPoint[1], cornerPoint[0], 0] = 0\n",
    "    point_corners[cornerPoint[1], cornerPoint[0], 1] = 0\n",
    "    point_corners[cornerPoint[1], cornerPoint[0], 2] = 0\n",
    "\n",
    "point_corners = point_corner\n",
    "\n",
    "cv2.imshow('Image with Point Corners 2', point_corners)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
