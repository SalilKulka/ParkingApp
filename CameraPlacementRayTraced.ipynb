{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module\n",
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imagePath = 'Images'\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "resizedImageName = imageName + \"_resized\"\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "img = cv2.imread(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def selectFarthestPoint(p1,ptList):\n",
    "    #returns either of p2 or p3 depending on which point is farthest away from p1 (mounting point)\n",
    "    maxDistance = 0\n",
    "    p = [0,0]\n",
    "    for pt in ptList:\n",
    "        d1 = abs(math.sqrt(math.pow(p1[0]-pt[0],2)+math.pow(p1[1]-pt[1],2)))\n",
    "        if(d1>maxDistance):\n",
    "            p[0] = pt[0]\n",
    "            p[1] = pt[1]\n",
    "            maxDistance = d1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def rangeCheck(checkAgainst,val,tolerance=0.01):\n",
    "    if(val>=checkAgainst*(1-tolerance) and val<=checkAgainst*(1+tolerance)):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def cornerCheck(p1,p2):\n",
    "    h,w = img.shape[:2]\n",
    "    if(rangeCheck(p1[1],h)):\n",
    "        if(rangeCheck(p2[0],w)):\n",
    "            return (w,h)\n",
    "        elif(rangeCheck(p2[0],0)):\n",
    "            return (0,h)\n",
    "    elif(rangeCheck(p2[1],h)):\n",
    "        if(rangeCheck(p1[0],w)):\n",
    "            return (w,h)\n",
    "        elif(rangeCheck(p1[0],0)):\n",
    "            return (0,h)\n",
    "    elif(rangeCheck(p1[1],0)):\n",
    "        if(rangeCheck(p2[0],w)):\n",
    "            return (w,0)\n",
    "        elif(rangeCheck(p2[0],0)):\n",
    "            return (0,0)\n",
    "    elif(rangeCheck(p2[1],0)):\n",
    "        if(rangeCheck(p1[0],w)):\n",
    "            return (w,0)\n",
    "        elif(rangeCheck(p1[0],0)):\n",
    "            return (0,0)\n",
    "        \n",
    "    return (-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def getResizedForDisplayImg(img):\n",
    "    screen_w, screen_h = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "    #print(\"screen size\",screen_w, screen_h)\n",
    "    h,w,channel_nbr = img.shape\n",
    "    # img get w of screen and adapt h\n",
    "    h = h * (screen_w / w)\n",
    "    w = screen_w\n",
    "    if h > screen_h: #if img h still too big\n",
    "        # img get h of screen and adapt w\n",
    "        w = w * (screen_h / h)\n",
    "        h = screen_h\n",
    "    w, h = w*0.9, h*0.9 # because you don't want it to be that big, right ?\n",
    "    w, h = int(w), int(h) # you need int for the cv2.resize\n",
    "    return cv2.resize(img, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def getMountingPoints(img):\n",
    "\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(imageCopy, low_red, low_red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # convert to grayscale\n",
    "    # operatedImage = cv2.cvtColor(combined_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # setting to 32-bit floating point\n",
    "    operatedImage = np.float32(combined_mask)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate values as input parameters\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 3, 0.04)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # draw on the output image\n",
    "    imageCopy[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    return imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def cluster2Point(clusterImg, img = np.zeros(img.shape, dtype='uint8')):\n",
    "# Make the corners into one point\n",
    "\n",
    "    # innitates the the single point corner arrays\n",
    "    Points = []\n",
    "\n",
    "    # blank = np.zeros(img.shape, dtype='uint8')\n",
    "    imageCopy = img.copy()\n",
    "    whiteMask = np.zeros(clusterImg.shape, dtype='uint8')\n",
    "    # create masks for the corner clusters\n",
    "    if(len(clusterImg.shape)==2):\n",
    "        white_mask = cv2.inRange(clusterImg, 255, 255)\n",
    "    elif(len(clusterImg.shape)==3):\n",
    "        white_mask = cv2.inRange(clusterImg, (255,255,255), (255,255,255))\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        Points.append([cx,cy])\n",
    "        imageCopy[cy, cx] = [255, 255, 255]\n",
    "        # cv2.circle(imageCopy, (cx, cy), 1, (255, 255, 255), -1)\n",
    "        # cv2.drawContours(blank, [i], -1, 0, -1)\n",
    "\n",
    "    return Points, imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def getRoadsnParkings(img):\n",
    "    \n",
    "    tempImg = img.copy()\n",
    "    # define color ranges\n",
    "    # blue_lower = (250,0,0)\n",
    "    blue = np.array([255, 0, 0], dtype=\"uint8\")\n",
    "\n",
    "    # create masks\n",
    "    blue_mask = cv2.inRange(img, blue, blue)\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    #combined_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\n",
    "    for c in cnts:\n",
    "        # area = cv2.contourArea(c)\n",
    "        # for eps in np.linspace(0.001, 0.005, 5):\n",
    "        #     # approximate the contour\n",
    "        #     peri = cv2.arcLength(c, True)\n",
    "        #     approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "        cv2.drawContours(tempImg, [c], -1, 0, -1)\n",
    "\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    #image = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return blue_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def pointGen(source, m, l):\n",
    "    # m is the slope of line, and the\n",
    "    # required Point lies distance l\n",
    "    # away from the source Point\n",
    "    a = Point(0, 0)\n",
    "    b = Point(0, 0)\n",
    "\n",
    "    # slope is 0\n",
    "    if m == 0:\n",
    "        a.x = source.x + l\n",
    "        a.y = source.y\n",
    "\n",
    "        b.x = source.x - l\n",
    "        b.y = source.y\n",
    "\n",
    "    # if slope is infinite\n",
    "    elif math.isfinite(m) is False:\n",
    "        a.x = source.x\n",
    "        a.y = source.y + l\n",
    "\n",
    "        b.x = source.x\n",
    "        b.y = source.y - l\n",
    "    else:\n",
    "        dx = (l / math.sqrt(1 + (m * m)))\n",
    "        dy = m * dx\n",
    "        a.x = source.x + dx\n",
    "        a.y = source.y + dy\n",
    "        b.x = source.x - dx\n",
    "        b.y = source.y - dy\n",
    "    \n",
    "    return [[a.x,a.y],[b.x,b.y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def detectCorner(image):\n",
    "\n",
    "    # making a copy of the image to have the original image untouched in main loop\n",
    "    imageSub = image.copy()\n",
    "\n",
    "    # convert to gray and perform Harris corner detection\n",
    "    gray = cv2.cvtColor(imageSub,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    \n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining mounting points from red buildings img\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "\n",
    "    # threshold for an optimal value, it may vary depending on the image.\n",
    "    imageSub[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "    return imageSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def click_Scale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        scalePoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 255, 0), 2)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        scalePoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        b = img[y, x, 0]\n",
    "        g = img[y, x, 1]\n",
    "        r = img[y, x, 2]\n",
    "        cv2.putText(img, str(b) + ',' +str(g) + ',' + str(r),(x,y), font, 1,(255, 255, 0), 2)\n",
    "        cv2.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def getBorderContour(img):\n",
    "#function runs only once\n",
    "#using new bgr values for the new image in low red.\n",
    "\n",
    "    img_c = img.copy()\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, red, red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "            # cv2.drawContours(blank, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "    \n",
    "    return blank, combined_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def drawLine(slope, point, img):\n",
    "    #draws line segment infinitely from edges of image\n",
    "\n",
    "    returnImage = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "    y_lim,x_lim = returnImage.shape\n",
    "    px,py,qx,qz = [-1,-1,-1,-1] #initialize variables with \n",
    "\n",
    "    if(slope==math.inf or -slope==math.inf):\n",
    "        px = point[0]\n",
    "        py = y_lim\n",
    "\n",
    "        qx = point[0]\n",
    "        qy = 0\n",
    "    else:\n",
    "        px = x_lim\n",
    "        py = slope*x_lim + (point[1] - slope*point[0])\n",
    "\n",
    "        qx = 0\n",
    "        qy = (point[1] - slope*point[0])\n",
    "\n",
    "    # cv2.line(returnImage, (int(px),int(py)),(int(qx), int(qy)), 255, 1)\n",
    "\n",
    "    try:        \n",
    "        cv2.line(returnImage, (int(px),int(py)),(int(qx), int(qy)), 255, 1)\n",
    "    except:\n",
    "        # print(slope, px, py, qx, qy)\n",
    "        pass\n",
    "    return returnImage  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def getRoadCoverageMask(selected_edge_list, cutQuadBorder, mountingPoint):\n",
    "    totalMask = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "    for selected_edge_contour in selected_edge_list:\n",
    "        #mask related to a single contour, to which individual line blocking masks will be OR'ed to \n",
    "        contourMask = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "        oneContourPic = np.zeros(img.shape, dtype='uint8')\n",
    "        cv2.drawContours(oneContourPic, [selected_edge_contour], -1, (255,255,255), thickness=1) #draws only selected contour for the loop\n",
    "        oneContourPic = cv2.cvtColor(oneContourPic, cv2.COLOR_BGR2GRAY)   #convert drawn picture into grayscale\n",
    "\n",
    "        oneContourPic = cv2.Canny(oneContourPic,50,150,apertureSize=3)\n",
    "\n",
    "        # Apply HoughLinesP method to \n",
    "        # to directly obtain line end points\n",
    "        lines = cv2.HoughLinesP(\n",
    "                    oneContourPic, # Input edge image\n",
    "                    1, # Distance resolution in pixels\n",
    "                    np.pi/180, # Angle resolution in radians\n",
    "                    threshold=11, # Min number of votes for valid line. Use lesser number of votes for smaller lines\n",
    "                    minLineLength=5, # Min allowed length of line\n",
    "                    maxLineGap=10 # Max allowed gap between line for joining them\n",
    "                    )\n",
    "\n",
    "        #same line is appearing in the pic twice, perhaps increase threshold (number of votes/points)\n",
    "        if(lines is None):\n",
    "            continue\n",
    "\n",
    "\n",
    "        for points in lines:\n",
    "\n",
    "            demo = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Extracted points nested in the list\n",
    "            x1,y1,x2,y2=points[0]\n",
    "\n",
    "            # Step 4: For each line AND it with the interior corner points ??\n",
    "\n",
    "            interiorPointCoords_1 = (x1, y1)\n",
    "            interiorPointCoords_2 = (x2, y2)\n",
    "\n",
    "            # Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "            # Step 6: Get the slope from the mounting point to those interior corners\n",
    "            # Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "            \n",
    "            joiningLine_1 = drawLine((mountingPoint[1] - interiorPointCoords_1[1])/(mountingPoint[0] - interiorPointCoords_1[0]), interiorPointCoords_1, img)\n",
    "            joiningLine_2 = drawLine((mountingPoint[1] - interiorPointCoords_2[1])/(mountingPoint[0] - interiorPointCoords_2[0]), interiorPointCoords_2, img)\n",
    "            \n",
    "            Point_1 = cv2.bitwise_and(cutQuadBorder, joiningLine_1)\n",
    "\n",
    "            PointCoords_1, _ = cluster2Point(Point_1)  #more than one cluster might form or no cluster might wrong\n",
    "            # print(PointCoords_1)\n",
    "            if(len(PointCoords_1)==0):  #weird case that you can't do anything about. Realistically this shouldn't exist, but it does\n",
    "                continue\n",
    "            if(len(PointCoords_1)==1):\n",
    "                PointCoords_1 = PointCoords_1[0]\n",
    "            elif(len(PointCoords_1)==2):\n",
    "                PointCoords_1 = selectFarthestPoint(mountingPoint, PointCoords_1)\n",
    "            elif(len(PointCoords_1)>2):\n",
    "                y,x = np.nonzero(Point_1)\n",
    "                y = list(y)\n",
    "                x = list(x)\n",
    "                pts = [(x[a], y[a]) for a in range(len(x))]\n",
    "                PointCoords_1 = selectFarthestPoint(mountingPoint, pts)\n",
    "\n",
    "            Point_2 = cv2.bitwise_and(cutQuadBorder, joiningLine_2)\n",
    "            PointCoords_2, _ = cluster2Point(Point_2)  #more than one cluster might form or no cluster might wrong\n",
    "            if(len(PointCoords_2)==0):  #weird case that you can't do anything about. Realistically this shouldn't exist, but it does\n",
    "                continue\n",
    "            if(len(PointCoords_2)==1):\n",
    "                PointCoords_2 = PointCoords_2[0]\n",
    "            elif(len(PointCoords_2)==2):\n",
    "                PointCoords_2 = selectFarthestPoint(mountingPoint, PointCoords_2)\n",
    "            elif(len(PointCoords_2)>2):\n",
    "                y,x = np.nonzero(Point_2)\n",
    "                y = list(y)\n",
    "                x = list(x)\n",
    "                pts = [(x[a], y[a]) for a in range(len(x))]\n",
    "                PointCoords_2 = selectFarthestPoint(mountingPoint, pts)\n",
    "\n",
    "            lineMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "            pointSet = [interiorPointCoords_1, interiorPointCoords_2, PointCoords_2, PointCoords_1]\n",
    "            # print(pointSet)\n",
    "            inclusionCorner = cornerCheck(PointCoords_1, PointCoords_2)\n",
    "            if(inclusionCorner[0]!=-1):\n",
    "                pointSet.insert(3,inclusionCorner)\n",
    "\n",
    "\n",
    "            # Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "            # There is a concern that the points are listed in not the correct order...\n",
    "            blockPts = np.array( pointSet, dtype=np.int32) #original\n",
    "            # blockPts = np.array( [interiorPointCoords_1, interiorPointCoords_2, PointCoords_2[0], PointCoords_1[0]], dtype=np.int32)  #working change by Atharva\n",
    "            blockPts = blockPts.reshape((-1, 1, 2))\n",
    "            lineMask = cv2.fillPoly(lineMask, pts=[blockPts],color=255)\n",
    "\n",
    "            # Step 9: OR all the quadrilateral generated inside the loop on the view quad mask\n",
    "            contourMask = cv2.bitwise_or(contourMask, lineMask)\n",
    "        totalMask = cv2.bitwise_or(totalMask, contourMask)\n",
    "    totalMask = cv2.bitwise_not(totalMask)\n",
    "    return totalMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def genQuadImages(pt):\n",
    "    cutQuadMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "    cutQuadBorder = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "    pt = pt.reshape((-1,1,2))\n",
    "    \n",
    "    cv2.fillPoly(cutQuadMask, [pt], 255)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(cutQuadMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        for eps in np.linspace(0.001, 0.01, 10):\n",
    "            # approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "        \n",
    "        # draw the approximated contour on the image  \n",
    "        cv2.drawContours(cutQuadBorder, [c], -1, (255,255,255), thickness=1)\n",
    "    return cutQuadMask, cutQuadBorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cython.cfunc\n",
    "def main(img, mountingPoint, ALPHA, beta, road, bldg_mask, bldg_brdr):\n",
    "    # loop vars\n",
    "    BETA = beta*math.pi/180\n",
    "    cameraRoadCoverage = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "\n",
    "    imgCopy = img.copy()\n",
    "    roadCopy = road.copy()\n",
    "\n",
    "    # distances of closer and further edges from mounting point\n",
    "    # closer_dist = heightPix[20]*math.tan(ALPHA - (phi/2))\n",
    "    further_dist = heightPix[20]*math.tan(ALPHA + (phi/2))\n",
    "\n",
    "    # slope of horizontal plane camera angle\n",
    "    slope_beta = math.tan(BETA)\n",
    "\n",
    "    # midpoints of closer and further edges\n",
    "    if beta > 180:\n",
    "        further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[1]\n",
    "    else:\n",
    "        further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[0]\n",
    "\n",
    "    further_edge =(heightPix[20]*math.tan(omega/2))/math.cos(ALPHA+(phi/2))\n",
    "\n",
    "    # Obtaining on ground triangle points\n",
    "    point1 = mountingPoint\n",
    "    point2 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[1]\n",
    "    point3 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[0]\n",
    "    \n",
    "    # plotting the points\n",
    "    pt = np.array([point1, point2, point3], np.int32)\n",
    "    cameraRoadCoverage, cutQuadBorder = genQuadImages(pt)\n",
    "\n",
    "    # code block to check if mounting point is directly viewing inside a bldg\n",
    "    circleCheck = np.zeros(img.shape[:2], dtype = \"uint8\")\n",
    "    cv2.circle(circleCheck, (mountingPoint[0], mountingPoint[1]), 3, 255, 1)\n",
    "    Check_step1 = cv2.bitwise_and(circleCheck, cameraRoadCoverage)\n",
    "    Check_step2 = cv2.bitwise_and(Check_step1, bldg_mask)\n",
    "\n",
    "    nonzeroX, _ = np.nonzero(Check_step2)\n",
    "    if len(nonzeroX)>0:\n",
    "        return \n",
    "    # --------------------------------#\n",
    "\n",
    "    # get building borders inside viewing quadrilateral\n",
    "    selected_bldg_brdrs_gray = cv2.cvtColor(cv2.bitwise_and(bldg_brdr,bldg_brdr, mask = cameraRoadCoverage), cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "    # \n",
    "    selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "    \n",
    "    roadCoveredMask = getRoadCoverageMask(selected_edge_list, cutQuadBorder, mountingPoint)\n",
    "\n",
    "    cameraRoadCoverage = cv2.bitwise_and(roadCopy, cameraRoadCoverage, mask = roadCoveredMask)\n",
    "    \n",
    "\n",
    "    # find the updated are of camera coverage\n",
    "    cameraRoadCoverageContour = cv2.findContours(cameraRoadCoverage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cameraRoadCoverageContour = cameraRoadCoverageContour[0] if len(cameraRoadCoverageContour) == 2 else cameraRoadCoverageContour[1]\n",
    "\n",
    "    \n",
    "    area_sum = 0\n",
    "    for contour in cameraRoadCoverageContour:\n",
    "        area = cv2.contourArea(contour)\n",
    "        area_sum += area\n",
    "    \n",
    "    return area_sum, cameraRoadCoverage, point1, point2, point3, roadCoveredMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxArea: cython.double\n",
    "fp1: cython.double\n",
    "fp2: cython.double\n",
    "fp3: cython.double\n",
    "maxCameraRoadCoverage: cython.double\n",
    "\n",
    "scalePoints: cython.int[(0)]\n",
    "mountingPoints: cython.int[(0)]\n",
    "\n",
    "theta: cython.double\n",
    "phi: cython.double\n",
    "omega: cython.double\n",
    "alpha: cython.double\n",
    "\n",
    "scaleConst: cython.double\n",
    "scale: cython.int\n",
    "heights: cython.int[0]\n",
    "heightPix: cython.int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalePoints = [(302, 373), (464, 373)] # points obtained from sample_scale.PNG map which is a google maps with the same dimensions\n",
    "\n",
    "maxArea = 0\n",
    "\n",
    "theta = (66.75*math.pi)/180    #diagonal angle FOV of camera (GIVEN!!)\n",
    "phi = 2*math.atan(0.8*math.tan(theta/2))  #angle of view larger side of camera resolution (4 in 4:3)\n",
    "omega = 2*math.atan(0.6*math.tan(theta/2))     #angle of view larger side of camera resolution (3 in 4:3)\n",
    "alpha = (75*math.pi)/180   #set later on in the code based on the height of the camera [angle of camera from negative z axis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale for pix to meter conversion\n",
    "# scaleConst = int(input('Scale: '))\n",
    "scaleConst = 20 # for the below pixel distance, this represent\n",
    "\n",
    "# Get mounting points from building borders\n",
    "# mountingPoints = get_MP_FromBuildings_ButAlsoText(img)\n",
    "\n",
    "# Pixel distance of scale in image\n",
    "# actual distance(m) = (scale constant)*(obtained magnitude)/scale\n",
    "scale = math.ceil(abs(math.sqrt(pow(scalePoints[0][0] - scalePoints[1][0],2) + pow(scalePoints[0][1] - scalePoints[1][1],2))))\n",
    "\n",
    "# heights = [x*0.1 for x in range(30,60)] #average height of light poles is 9 to 14 feet ~ 4.2m max\n",
    "heights = [h*0.1 for h in range(30, 60)]    #3m to 6m\n",
    "# Converting height in meter array to height in pixel array\n",
    "heightPix = [h*scale/scaleConst for h in heights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the resized the image\n",
    "# img = cv2.imread(imagePath)\n",
    "\n",
    "# obtaining the mask of the roads and parkings in the map image\n",
    "road = getRoadsnParkings(img)   #image is grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('win', road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "\n",
    "mountingCluster = getMountingPoints(img)\n",
    "mountingPointsList, mountingPointsImg = cluster2Point(mountingCluster, img)\n",
    "\n",
    "cv2.imshow(\"mounting points as pixels\", mountingPointsImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting building borders by using a mask function\n",
    "bldg_brdr, bldg_mask = getBorderContour(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salil kulkarni\\AppData\\Local\\Temp\\ipykernel_676\\757620607.py:46: RuntimeWarning: divide by zero encountered in int_scalars\n",
      "  joiningLine_1 = drawLine((mountingPoint[1] - interiorPointCoords_1[1])/(mountingPoint[0] - interiorPointCoords_1[0]), interiorPointCoords_1, img)\n",
      "C:\\Users\\Salil kulkarni\\AppData\\Local\\Temp\\ipykernel_676\\757620607.py:47: RuntimeWarning: divide by zero encountered in int_scalars\n",
      "  joiningLine_2 = drawLine((mountingPoint[1] - interiorPointCoords_2[1])/(mountingPoint[0] - interiorPointCoords_2[0]), interiorPointCoords_2, img)\n",
      "C:\\Users\\Salil kulkarni\\AppData\\Local\\Temp\\ipykernel_676\\757620607.py:46: RuntimeWarning: invalid value encountered in int_scalars\n",
      "  joiningLine_1 = drawLine((mountingPoint[1] - interiorPointCoords_1[1])/(mountingPoint[0] - interiorPointCoords_1[0]), interiorPointCoords_1, img)\n",
      "C:\\Users\\Salil kulkarni\\AppData\\Local\\Temp\\ipykernel_676\\757620607.py:47: RuntimeWarning: invalid value encountered in int_scalars\n",
      "  joiningLine_2 = drawLine((mountingPoint[1] - interiorPointCoords_2[1])/(mountingPoint[0] - interiorPointCoords_2[0]), interiorPointCoords_2, img)\n"
     ]
    }
   ],
   "source": [
    "# angle of camera from negative of vertical axisS\n",
    "img = cv2.imread(imagePath)\n",
    "ALPHA = 60*math.pi/180\n",
    "\n",
    "for mountingPoint in mountingPointsList:\n",
    "    for beta in range (0,360, 10):\n",
    "\n",
    "        # beta edge cases\n",
    "        if(beta==180 or beta==0 or beta==360):\n",
    "            continue\n",
    "\n",
    "        # loop vars\n",
    "        BETA = beta*math.pi/180\n",
    "        cameraRoadCoverage = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "\n",
    "        imgCopy = img.copy()\n",
    "        roadCopy = road.copy()\n",
    "\n",
    "        # distances of closer and further edges from mounting point\n",
    "        # closer_dist = heightPix[20]*math.tan(ALPHA - (phi/2))\n",
    "        further_dist = heightPix[20]*math.tan(ALPHA + (phi/2))\n",
    "\n",
    "        # slope of horizontal plane camera angle\n",
    "        slope_beta = math.tan(BETA)\n",
    "\n",
    "        # midpoints of closer and further edges\n",
    "        if beta > 180:\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[1]\n",
    "        else:\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[0]\n",
    "\n",
    "        further_edge =(heightPix[20]*math.tan(omega/2))/math.cos(ALPHA+(phi/2))\n",
    "\n",
    "        # Obtaining on ground triangle points\n",
    "        point1 = mountingPoint\n",
    "        point2 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[1]\n",
    "        point3 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[0]\n",
    "        \n",
    "        # plotting the points\n",
    "        pt = np.array([point1, point2, point3], np.int32)\n",
    "        cameraRoadCoverage, cutQuadBorder = genQuadImages(pt)\n",
    "\n",
    "        # code block to check if mounting point is directly viewing inside a bldg\n",
    "        circleCheck = np.zeros(img.shape[:2], dtype = \"uint8\")\n",
    "        cv2.circle(circleCheck, (mountingPoint[0], mountingPoint[1]), 3, 255, 1)\n",
    "        Check_step1 = cv2.bitwise_and(circleCheck, cameraRoadCoverage)\n",
    "        Check_step2 = cv2.bitwise_and(Check_step1, bldg_mask)\n",
    "\n",
    "        nonzeroX, _ = np.nonzero(Check_step2)\n",
    "        if len(nonzeroX)>0:\n",
    "            continue\n",
    "        # --------------------------------#\n",
    "\n",
    "        # get building borders inside viewing quadrilateral\n",
    "        selected_bldg_brdrs_gray = cv2.cvtColor(cv2.bitwise_and(bldg_brdr,bldg_brdr, mask = cameraRoadCoverage), cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "        # \n",
    "        selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "        \n",
    "        roadCoveredMask = getRoadCoverageMask(selected_edge_list, cutQuadBorder, mountingPoint)\n",
    "\n",
    "        cameraRoadCoverage = cv2.bitwise_and(roadCopy, cameraRoadCoverage, mask = roadCoveredMask)\n",
    "        \n",
    "\n",
    "        # find the updated are of camera coverage\n",
    "        cameraRoadCoverageContour = cv2.findContours(cameraRoadCoverage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cameraRoadCoverageContour = cameraRoadCoverageContour[0] if len(cameraRoadCoverageContour) == 2 else cameraRoadCoverageContour[1]\n",
    "\n",
    "        \n",
    "        area_sum = 0\n",
    "        for contour in cameraRoadCoverageContour:\n",
    "            area = cv2.contourArea(contour)\n",
    "            area_sum += area\n",
    "\n",
    "        if area_sum > maxArea:\n",
    "            maxArea = area_sum\n",
    "            fp1 = point1\n",
    "            fp2 = point2\n",
    "            fp3 = point3\n",
    "            mp = mountingPoint\n",
    "            excludedRoad = roadCoveredMask\n",
    "            maxCameraRoadCoverage = cv2.bitwise_or(cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY), cameraRoadCoverage)\n",
    "\n",
    "        \n",
    "\n",
    "try:\n",
    "    # plotting best shape and the mounting point\n",
    "    pts = np.array([fp1, fp2, fp3], np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    cv2.polylines(img, [pts], True, (255,255,0))\n",
    "    cv2.circle(img, (mp[0], mp[1]), 5, (255,0,0),2)\n",
    "\n",
    "\n",
    "    cv2.polylines(maxCameraRoadCoverage, [pts], True, (255,255,0))\n",
    "    cv2.circle(maxCameraRoadCoverage, (mp[0], mp[1]), 5, (255,0,0),2)\n",
    "except:\n",
    "    print(fp1, fp2, fp3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing image\n",
    "cv2.imshow('included', maxCameraRoadCoverage)\n",
    "# cv2.imshow('excluded', GlobalCheck1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
