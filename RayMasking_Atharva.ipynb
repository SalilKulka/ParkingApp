{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#NEVER USE NP.ADD always use CV2.BITWISE_OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Images'\n",
    "# Image path\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "\n",
    "# read image \n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "mountingPoints = []\n",
    "quadPoints = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to do test/implement ray masking\n",
    "1. Plot out viewing quadrilateral\n",
    "2. Plot out mounting point\n",
    "3. Mask out for building contours\n",
    "4. Find corners of building contours\n",
    "\n",
    "Taking the nearest corner, find the slope of the line joining the mounting point and this nearest corner. Find the intersection point of this line and the farthest edge of the quadrilateral (What if farthest edge is out of bounds ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderContour_text(img):\n",
    "#function runs only once\n",
    "#using new bgr values for the new image in low red.\n",
    "\n",
    "    img_c = img.copy()\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "    high_yellow = (242,251,256)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, low_red, low_red )\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "            # cv2.drawContours(blank, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return blank, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mountingPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 0, 0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        quadPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y),(x,y), font, 1,(0, 0, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners(buildingBorderMask, quadPts, blocksize=3):\n",
    "\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "    # for obtaining corners for ray masking\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "\n",
    "    # Mask may have 3 layers\n",
    "    operatedImage = cv2.cvtColor(buildingBorderMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) \n",
    "\n",
    "    # modify the data type -- setting to 32-bit floating point\n",
    "    operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method to detect the corners with appropriate values as input parameters\n",
    "    # increase the second parameter ~ blocksize to get more of the corner shape out\n",
    "    dest = cv2.cornerHarris(operatedImage, blocksize, 5, 0.07)  \n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # a mask of all corners of the building contours\n",
    "    cornerMask = np.zeros(buildingBorderMask.shape, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    # Make a gray scale mask of quadilateral area\n",
    "    quadMask = np.zeros(buildingBorderMask.shape[:2], dtype='uint8')\n",
    "    polyPts = np.array( quadPts ,dtype=np.int32)\n",
    "    polyPts = polyPts.reshape((-1, 1, 2))\n",
    "    quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "    # a mask of all corners in quadilateral only\n",
    "    cornerMask = cv2.bitwise_and(cornerMask,cornerMask,mask=quadMask)\n",
    "\n",
    "    return cornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClusterCenters(img, excludedCornerPoints = []):\n",
    "\n",
    "    corner_centers = []\n",
    "\n",
    "    onePixCornerMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "    # blank_copy = blank.copy()\n",
    "\n",
    "    white_mask = np.zeros(img.shape, dtype = 'uint8')\n",
    "\n",
    "    if(len(img.shape)==3):\n",
    "        white_mask = cv2.inRange(img, (255,255,255), (255,255,255))\n",
    "    else:\n",
    "        white_mask = cv2.inRange(img, 255, 255)\n",
    "\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        if([cx,cy] not in excludedCornerPoints):\n",
    "            onePixCornerMask[cy,cx] = 255\n",
    "            # cv2.circle(onePixCornerMask, (cx, cy), 1, (255, 255, 255), -1)\n",
    "            corner_centers.append([cx,cy])\n",
    "\n",
    "\n",
    "    return corner_centers, onePixCornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners_w_exclude(img, cornerPoints=[]):\n",
    "    \n",
    "    operatedImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # modify the data type\n",
    "    # setting to 32-bit floating point\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate\n",
    "    # values as input parameters\n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining corners for ray masking\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # for pts in poly_pts:\n",
    "    #     dest[pts[0]][pts[1]] = 0\n",
    "    # Reverting back to the original image,\n",
    "    # with optimal threshold value\n",
    "    size = img.shape\n",
    "\n",
    "    cornerMask = np.zeros(size, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    points,cornerMask = findClusterCenters(cornerMask,cornerPoints)\n",
    "\n",
    "    return cornerMask, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(slope, point):\n",
    "    #draws line segment infinitely from edges of image\n",
    "\n",
    "    returnImage = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "    y_lim,x_lim = returnImage.shape\n",
    "    px,py,qx,qz = [-1,-1,-1,-1] #initialize variables with \n",
    "\n",
    "    if(slope==-1):\n",
    "        px = point[0]\n",
    "        py = y_lim\n",
    "\n",
    "        qx = point[0]\n",
    "        qy = 0\n",
    "    else:\n",
    "        px = x_lim\n",
    "        py = slope*x_lim + (point[1] - slope*point[0])\n",
    "\n",
    "        qx = 0\n",
    "        qy = (point[1] - slope*point[0])\n",
    "        \n",
    "    cv2.line(returnImage, (int(px),int(py)),(int(qx), int(qy)), 255, 1)\n",
    "    return returnImage  \n",
    "\n",
    "cv2.imshow(\"one contour\", drawLine(1, (200,200)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Detect all corners in the image and mask out the view quadrilateral.. to get point only in the interior of the quad\\n\n",
    "##### Step 2: Mask out the view quadrilateral in the original img and then run corner detection.. to get all points interior and on edge\n",
    "##### Step 3: Loop through every line of every contour inside quad\n",
    "##### Step 4: For each line AND it with the interior corner points\n",
    "##### Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "##### Step 6: Get the slope from the mounting point to those interior corners\n",
    "##### Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "##### Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "##### Step 9: OR all the quadrilateral generated inside the loop on the view quad mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display image \n",
    "img = cv2.imread(imagePath)\n",
    "cv2.imshow(\"img\",img)\n",
    "\n",
    "# right click = view quadilateral (4+)\n",
    "# left click = mounting point (1)\n",
    "cv2.setMouseCallback('img', click_MountingnScale_points)\n",
    "# points are to be selected in the order - \n",
    "# click 1 = nearest edge left point = quadPoints[0]\n",
    "# click 2 = nearest edge right point = quadPoints[1]\n",
    "# click 3 = further edge right point = quadPoints[2]\n",
    "# click 4 = further edge left point = quadPoints[3]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building contours on black image and building mask\n",
    "bldg_brdrs, bldg_mask = getBorderContour_text(img)\n",
    "\n",
    "# gather quadrilateral points\n",
    "polyPts = np.array( quadPoints ,dtype=np.int32)\n",
    "polyPts = polyPts.reshape((-1, 1, 2))\n",
    "\n",
    "# make viewing quadrilateral mask\n",
    "quadMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "# get building borders inside viewing quadrilateral\n",
    "selected_bldg_brdrs = cv2.bitwise_and(bldg_brdrs,bldg_brdrs, mask = quadMask)\n",
    "selected_bldg_brdrs_gray = cv2.cvtColor(selected_bldg_brdrs, cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "# \n",
    "selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "\n",
    "# all_selected_corner = cv2.bitwise_and(bldg_brdrs, quadMask)\n",
    "# all_selected_corner = getCorners(all_selected_corner)\n",
    "\n",
    "# building corners inside viewing quadrilateral\n",
    "original_corners = getCorners(bldg_brdrs, quadPoints)\n",
    "original_corners_g = cv2.cvtColor(original_corners, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 1: Detect all corners in the image and mask out the view quadrilateral.. to get point only in the interior of the quad\n",
    "_, cornerPix = findClusterCenters(original_corners) #cornerPix is all corner on the inside of the view quadrilateral\n",
    "\n",
    "# Points displayed on img\n",
    "# imgCornerPix = np.add(img, original_corners)\n",
    "\n",
    "cv2.imshow(\"bldg_brdrs\",cornerPix)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Mask out the view quadrilateral in the original img and then run corner detection.. to get all points interior and on edge\n",
    "bldg_borders_view_masked = cv2.bitwise_and(bldg_brdrs, bldg_brdrs, mask = quadMask)\n",
    "all_corners_found = getCorners(bldg_borders_view_masked, quadPoints)\n",
    "all_corners_found = findClusterCenters(all_corners_found)   #all corners on the interior and on edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use two masks to distinguish points on the side edges vs points on the nearest edge\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "sideEdgeMask_1 = cv2.line(blank, quadPoints[1], quadPoints[2], 255, 1) #plot right edge\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "sideEdgeMask_2 = cv2.line(blank, quadPoints[0], quadPoints[3], 255, 1)   #plot left edge\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "nearestEdgeMask = cv2.line(blank, quadPoints[0], quadPoints[1], 255, 1)   #plot nearest edge\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "farthestEdgeMask = cv2.line(blank, quadPoints[2], quadPoints[3], 255, 1)   #plot farthest edge\n",
    "\n",
    "# cv2.imshow(\"farthest edge\", farthestEdgeMask)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_outline = np.zeros(bldg_brdrs.shape[:2], dtype='uint8')\n",
    "cv2.polylines(quad_outline, [polyPts],True, 255, 1)\n",
    "mountingPoint = mountingPoints[0]\n",
    "\n",
    "# Step 3: Loop through every line of every contour inside quad\n",
    "# for selected_edge_contour in selected_edge_list:\n",
    "\n",
    "selected_edge_contour = selected_edge_list[0]\n",
    "\n",
    "#mask related to a single contour, to which individual line blocking masks will be OR'ed to \n",
    "totalMask = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "oneContourPic = np.zeros(img.shape, dtype='uint8')\n",
    "cv2.drawContours(oneContourPic, [selected_edge_contour], -1, (255,255,255), thickness=1) #draws only selected contour for the loop\n",
    "oneContourPic = cv2.cvtColor(oneContourPic, cv2.COLOR_BGR2GRAY)   #convert drawn picture into grayscale\n",
    "\n",
    "cv2.imshow(\"one contour\", oneContourPic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "oneContourPic = cv2.Canny(oneContourPic,50,150,apertureSize=3)\n",
    "# cv2.imshow(\"one Contour\", oneContourPic)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Apply HoughLinesP method to \n",
    "# to directly obtain line end points\n",
    "lines = cv2.HoughLinesP(\n",
    "            oneContourPic, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=10, # Min number of votes for valid line. Use lesser number of votes for smaller lines\n",
    "            minLineLength=5, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    "for points in lines:\n",
    "\n",
    "    # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "\n",
    "    # Step 4: For each line AND it with the interior corner points ??\n",
    "\n",
    "    interiorPointCoords_1 = [y1, x1]\n",
    "    interiorPointCoords_2 = [y2, x2]\n",
    "\n",
    "    # Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "    # Step 6: Get the slope from the mounting point to those interior corners\n",
    "    # Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "    \n",
    "    joiningLine_1 = drawLine((mountingPoint[1] - interiorPointCoords_1[1])/(mountingPoint[0] - interiorPointCoords_1[0]), interiorPointCoords_1)\n",
    "    joiningLine_2 = drawLine((mountingPoint[1] - interiorPointCoords_2[1])/(mountingPoint[0] - interiorPointCoords_2[0]), interiorPointCoords_2)\n",
    "    \n",
    "    farthestEdgePoint_1 = cv2.bitwise_and(farthestEdgeMask, joiningLine_1)\n",
    "    farthestEdgePointCoords_1, _ = findClusterCenters(farthestEdgePoint_1)  #more than one cluster might form - worry !!\n",
    "    farthestEdgePointCoords_1 = farthestEdgePointCoords_1[0]\n",
    "\n",
    "    farthestEdgePoint_2 = cv2.bitwise_and(farthestEdgeMask, joiningLine_2)\n",
    "    farthestEdgePointCoords_2, _ = findClusterCenters(farthestEdgePoint_2)  #more than one cluster might form - worry !!\n",
    "    farthestEdgePointCoords_2 = farthestEdgePointCoords_2[0]\n",
    "\n",
    "    cv2.imshow(\"Farthest Edge Point\", farthestEdgePoint_2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    lineMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "    # Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "    # There is a concern that the points are listed in not the correct order...\n",
    "    blockPts = np.array( [interiorPointCoords_1, interiorPointCoords_2, farthestEdgePointCoords_1, farthestEdgePointCoords_2] ,dtype=np.int32)\n",
    "    blockPts = blockPts.reshape((-1, 1, 2))\n",
    "    lineMask = cv2.fillPoly(lineMask, pts=[blockPts],color=255)\n",
    "\n",
    "    # Step 9: OR all the quadrilateral generated inside the loop on the view quad mask\n",
    "    totalMask = cv2.bitwise_or(totalMask, lineMask)\n",
    "\n",
    "\n",
    "totalMask = cv2.bitwise_not(totalMask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
