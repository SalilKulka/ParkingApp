{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Images'\n",
    "# Image path\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "\n",
    "mountingPoints = []\n",
    "quadPoints = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to do test/implement ray masking\n",
    "1. Plot out viewing quadrilateral\n",
    "2. Plot out mounting point\n",
    "3. Mask out for building contours\n",
    "4. Find corners of building contours\n",
    "\n",
    "Taking the nearest corner, find the slope of the line joining the mounting point and this nearest corner. Find the intersection point of this line and the farthest edge of the quadrilateral (What if farthest edge is out of bounds ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderContour_text(img):\n",
    "#function runs only once\n",
    "#using new bgr values for the new image in low red.\n",
    "\n",
    "    img_c = img.copy()\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "    high_yellow = (242,251,256)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, low_red, low_red )\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "            # cv2.drawContours(blank, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return blank, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mountingPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 0, 0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        quadPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y),(x,y), font, 1,(0, 0, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners(buildingBorderMask, quadPts, blocksize=3):\n",
    "\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "    # for obtaining corners for ray masking\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "\n",
    "    # Mask may have 3 layers\n",
    "    operatedImage = cv2.cvtColor(buildingBorderMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) \n",
    "\n",
    "    # modify the data type -- setting to 32-bit floating point\n",
    "    operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method to detect the corners with appropriate values as input parameters\n",
    "    # increase the second parameter ~ blocksize to get more of the corner shape out\n",
    "    dest = cv2.cornerHarris(operatedImage, blocksize, 5, 0.07)  \n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # a mask of all corners of the building contours\n",
    "    cornerMask = np.zeros(buildingBorderMask.shape, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    # Make a gray scale mask of quadilateral area\n",
    "    quadMask = np.zeros(buildingBorderMask.shape[:2], dtype='uint8')\n",
    "    polyPts = np.array( quadPts ,dtype=np.int32)\n",
    "    polyPts = polyPts.reshape((-1, 1, 2))\n",
    "    quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "    # a mask of all corners in quadilateral only\n",
    "    cornerMask = cv2.bitwise_and(cornerMask,cornerMask,mask=quadMask)\n",
    "\n",
    "    return cornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClusterCenters(img, excludedCornerPoints = []):\n",
    "\n",
    "    corner_centers = []\n",
    "\n",
    "    onePixCornerMask = np.zeros(img.shape, dtype='uint8')\n",
    "    # blank_copy = blank.copy()\n",
    "\n",
    "    # create masks\n",
    "    white_mask = cv2.inRange(img, (255,255,255), (255,255,255))\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        if([cx,cy] not in excludedCornerPoints):\n",
    "            onePixCornerMask[cy, cx] = [255, 255, 255]\n",
    "            # cv2.circle(onePixCornerMask, (cx, cy), 1, (255, 255, 255), -1)\n",
    "            corner_centers.append([cx,cy])\n",
    "\n",
    "    onePixCornerMask = cv2.cvtColor(onePixCornerMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return corner_centers, onePixCornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners_w_exclude(img, cornerPoints=[]):\n",
    "    \n",
    "    operatedImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # modify the data type\n",
    "    # setting to 32-bit floating point\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate\n",
    "    # values as input parameters\n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining corners for ray masking\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # for pts in poly_pts:\n",
    "    #     dest[pts[0]][pts[1]] = 0\n",
    "    # Reverting back to the original image,\n",
    "    # with optimal threshold value\n",
    "    size = img.shape\n",
    "\n",
    "    cornerMask = np.zeros(size, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    points,cornerMask = findClusterCenters(cornerMask,cornerPoints)\n",
    "\n",
    "    return cornerMask, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display image \n",
    "img = cv2.imread(imagePath)\n",
    "cv2.imshow(\"img\",img)\n",
    "\n",
    "# right click = view quadilateral (4+)\n",
    "# left click = mounting point (1)\n",
    "cv2.setMouseCallback('img', click_MountingnScale_points)\n",
    "# points are to be selected in the order - \n",
    "# click 1 = nearest edge left point = quadPoints[0]\n",
    "# click 2 = nearest edge right point = quadPoints[1]\n",
    "# click 3 = further edge right point = quadPoints[2]\n",
    "# click 4 = further edge left point = quadPoints[3]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image \n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "# building contours on black image and building mask\n",
    "bldg_brdrs, bldg_mask = getBorderContour_text(img)\n",
    "\n",
    "# gather quadrilateral points\n",
    "polyPts = np.array( quadPoints ,dtype=np.int32)\n",
    "polyPts = polyPts.reshape((-1, 1, 2))\n",
    "\n",
    "# make viewing quadrilateral mask\n",
    "quadMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "# get building borders inside viewing quadrilateral\n",
    "selected_bldg_brdrs = cv2.bitwise_and(bldg_brdrs,bldg_brdrs, mask = quadMask)\n",
    "selected_bldg_brdrs_gray = cv2.cvtColor(selected_bldg_brdrs, cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "# \n",
    "selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "\n",
    "# all_selected_corner = cv2.bitwise_and(bldg_brdrs, quadMask)\n",
    "# all_selected_corner = getCorners(all_selected_corner)\n",
    "\n",
    "# building corners inside viewing quadrilateral\n",
    "original_corners = getCorners(bldg_brdrs, quadPoints)\n",
    "original_corners_g = cv2.cvtColor(original_corners, cv2.COLOR_BGR2GRAY)\n",
    "_, cornerPix = findClusterCenters(original_corners) #cornerPix is all corner on the inside of the view quadrilateral\n",
    "\n",
    "# Points displayed on img\n",
    "# imgCornerPix = np.add(img, original_corners)\n",
    "\n",
    "cv2.imshow(\"bldg_brdrs\",cornerPix)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Detect all corners in the image and mask out the view quadrilateral.. to get point only in the interior of the quad\n",
    "# Step 2: Mask out the view quadrilateral in the original img and then run corner detection.. to get all points interior and on edge\n",
    "# Step 3: Loop through every line of every contour inside quad\n",
    "# Step 4: For each line AND it with the interior corner points\n",
    "# Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "# Step 6: Get the slope from the mounting point to those interior corners\n",
    "# Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "# Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "# Step 9: OR all the quadrilateral generated inside the loop on the view quad mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_borders_view_masked = cv2.bitwise_and(bldg_brdrs, quadMask)\n",
    "all_corners_found = getCorners(bldg_borders_view_masked, quadPoints)\n",
    "all_corners_found = findClusterCenters(all_corners_found)   #all corners on the interior and on edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate loop vars\n",
    "quad_outline = np.zeros(bldg_brdrs.shape[:2], dtype='uint8')\n",
    "one_edge_pic = np.zeros(bldg_brdrs.shape, dtype='uint8')\n",
    "\n",
    "#Doing further calculation based on selected_edge_list[0], but in main code loop over all contours\n",
    "for selected_edge_contour in selected_edge_list:\n",
    "\n",
    "    #there is a chance that there are 2 corners caught in one contour. What to do here ? Choose the more inn\n",
    "\n",
    "    # border of viewing quadrilateral\n",
    "    cv2.polylines(quad_outline, [polyPts],True, 255, 1)\n",
    "\n",
    "    # draws only the selected countor of the for loopcv2.drawContours(one_edge_pic, [selected_edge_contour], -1, (255,255,255), thickness=1)\n",
    "\n",
    "  \n",
    "\n",
    "    #to get points associated  # nearest_edge_points = cv2.bitwise_and(nearest_edge_points, )\n",
    "\n",
    "    # finding corners on the selected loop contour\n",
    "    highlightedCorner = getCorners(one_edge_pic, quadPoints)\n",
    "    #for all corners in the list (real and generated)\n",
    "    #real corners = actual building corners\n",
    "    #generated corners = building corners generated by viewing quadrilateral cut offs\n",
    "    cornerPoint, highlightedCorner = findClusterCenters(highlightedCorner)\n",
    "\n",
    "    highlightedCorner = cv2.bitwise_and(original_corners_g,highlightedCorner)\n",
    "\n",
    "    # intersection of viewing quadrilateral and selected contour\n",
    "    sample = cv2.bitwise_and(one_edge_pic, one_edge_pic,mask = quad_outline)\n",
    "    cornerCoord, sample = findClusterCenters(sample)\n",
    "\n",
    "    #code in lines to check whether or not there are 2 points detected\n",
    "    #sometimes there can be only 1 or even no points\n",
    "\n",
    "    #initially set these 2 points to invalid coordinates. Fill each of these points depending on the number intersection points returned from \n",
    "    #image manipulations\n",
    "    intersection_pt_1 = [-1,-1]\n",
    "    intersection_pt_2 = [-1,-1]\n",
    "\n",
    "    if(len(cornerCoord)>0):\n",
    "        if(len(cornerCoord)>=1):\n",
    "            intersection_pt_1 = [cornerCoord[0][0],cornerCoord[0][1]]\n",
    "        if(len(cornerCoord)>=2):\n",
    "            intersection_pt_2 = [cornerCoord[1][0],cornerCoord[1][1]]\n",
    "\n",
    "    img_final = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "    mask_1_pts = np.array( [intersection_pt_1, cornerPoint[0], intersection_pt_1_1, slope_intersection_pt] ,dtype=np.int32)\n",
    "    mask_1_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "    mask_1 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "    mask_1 = cv2.fillPoly(mask_1, pts=[mask_1_pts],color = 255)\n",
    "    mask_1_inverted = cv2.bitwise_and(mask_1, quadMask)\n",
    "    mask_1 = cv2.bitwise_not(mask_1_inverted)\n",
    "\n",
    "cv2.imshow(\"selected corner\",highlightedCorner)\n",
    "cv2.imshow(\"selected contour\",one_edge_pic)\n",
    "cv2.imshow(\"selected intersections\",sample)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "16305.0\n",
      "354\n",
      "12517.5\n"
     ]
    }
   ],
   "source": [
    "#for each point, need to decide which farthest edge point constitutes the last point\n",
    "#eqs of side edges of viewing quadrilateral\n",
    "slope_left_edge = (quadPoints[3][1] - quadPoints[0][1])/(quadPoints[3][0] - quadPoints[0][0])\n",
    "slope_right_edge = (quadPoints[2][1] - quadPoints[1][1])/(quadPoints[2][0] - quadPoints[1][0])\n",
    "c_left_edge = quadPoints[3][1] - slope_left_edge*quadPoints[3][0]\n",
    "c_right_edge = quadPoints[1][1] - slope_left_edge*quadPoints[1][0]\n",
    "\n",
    "intersection_pt_1_1 = [-1,-1] #assign the point to the right most point of viewing quad initially, change if the condition below is satisfied\n",
    "intersection_pt_2_2 = [-1,-1] #assign the point to the right most point of viewing quad initially, change if the condition below is satisfied\n",
    "\n",
    "# what if one of the points lies on nearest edge/farthest edge. if both the points lie on the nearest/farthest edge\n",
    "# ideally, for a given building, if one of the building endings lies on the left edge, the corresponding 4th ed \n",
    "\n",
    "if(intersection_pt_1[0]!=-1):   #if intersection_pt_1 has valid info inside it (i.e. if it was found)\n",
    "    print(intersection_pt_1[1])\n",
    "    print(slope_left_edge*intersection_pt_1[0] + c_left_edge)\n",
    "    if(intersection_pt_1[1] == (slope_left_edge*intersection_pt_1[0] + c_left_edge)):   #check if intersection pt 1 lies on left edge\n",
    "        intersection_pt_1_1 = quadPoints[3]\n",
    "    else:\n",
    "        intersection_pt_1_1 = quadPoints[2] #set to right edge point\n",
    "\n",
    "if(intersection_pt_2[0]!=-1):   #if intersection_pt_2 has valid info inside it (i.e. if it was found)\n",
    "    print(intersection_pt_2[1])\n",
    "    print(slope_left_edge*intersection_pt_2[0] + c_left_edge)\n",
    "    if(intersection_pt_2[1] == (slope_left_edge*intersection_pt_2[0] + c_left_edge)):   #check if intersection pt 2 lies on left edge\n",
    "        intersection_pt_2_2 = quadPoints[3]\n",
    "    else:\n",
    "        intersection_pt_2_2 = quadPoints[2] #set to right edge point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "img_final = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "\n",
    "mask_1_pts = np.array( [intersection_pt_1, cornerPoint[0], intersection_pt_1_1, slope_intersection_pt] ,dtype=np.int32)\n",
    "mask_1_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "mask_1 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "mask_1 = cv2.fillPoly(mask_1, pts=[mask_1_pts],color = 255)\n",
    "mask_1_inverted = cv2.bitwise_and(mask_1, quadMask)\n",
    "mask_1 = cv2.bitwise_not(mask_1_inverted)\n",
    "#~~~~~~~~~#\n",
    "#NOT IMPLEMENTED YET\n",
    "#order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "mask_2_pts = np.array( [intersection_pt_2, cornerPoint[0], intersection_pt_2_2,slope_intersection_pt] ,dtype=np.int32)\n",
    "mask_2_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "mask_2 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "mask_2 = cv2.fillPoly(mask_2, pts=[mask_2_pts],color = 255)\n",
    "mask_2_inverted = cv2.bitwise_and(mask_2, quadMask)\n",
    "mask_2 = cv2.bitwise_not(mask_2_inverted)\n",
    "#~~~~~~~~#\n",
    "\n",
    "combined_mask = np.add(mask_1_inverted, mask_2_inverted)\n",
    "combined_mask = cv2.bitwise_not(combined_mask)\n",
    "\n",
    "img_final = cv2.bitwise_and(img_final, mask_1)\n",
    "img_final = cv2.bitwise_or(img_final, quad_outline)\n",
    "\n",
    "mask_diff = np.subtract(mask_1, mask_2)\n",
    "\n",
    "cv2.imshow(\"img final\",img_final)\n",
    "cv2.imshow(\"subtract mask 1\",mask_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
