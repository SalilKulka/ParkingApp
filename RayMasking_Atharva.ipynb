{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Images'\n",
    "# Image path\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "\n",
    "mountingPoints = []\n",
    "quadPoints = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to do test/implement ray masking\n",
    "1. Plot out viewing quadrilateral\n",
    "2. Plot out mounting point\n",
    "3. Mask out for building contours\n",
    "4. Find corners of building contours\n",
    "\n",
    "Taking the nearest corner, find the slope of the line joining the mounting point and this nearest corner. Find the intersection point of this line and the farthest edge of the quadrilateral (What if farthest edge is out of bounds ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderContour_text(img):\n",
    "#function runs only once\n",
    "#using new bgr values for the new image in low red.\n",
    "\n",
    "    img_c = img.copy()\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "    high_yellow = (242,251,256)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, low_red, low_red )\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "            # cv2.drawContours(blank, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return blank, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mountingPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 0, 0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        quadPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y),(x,y), font, 1,(0, 0, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners(buildingBorderMask, quadPts, blocksize=3):\n",
    "\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "    # for obtaining corners for ray masking\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "\n",
    "    # Mask may have 3 layers\n",
    "    operatedImage = cv2.cvtColor(buildingBorderMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) \n",
    "\n",
    "    # modify the data type -- setting to 32-bit floating point\n",
    "    operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method to detect the corners with appropriate values as input parameters\n",
    "    # increase the second parameter ~ blocksize to get more of the corner shape out\n",
    "    dest = cv2.cornerHarris(operatedImage, blocksize, 5, 0.07)  \n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # a mask of all corners of the building contours\n",
    "    cornerMask = np.zeros(buildingBorderMask.shape, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    # Make a gray scale mask of quadilateral area\n",
    "    quadMask = np.zeros(buildingBorderMask.shape[:2], dtype='uint8')\n",
    "    polyPts = np.array( quadPts ,dtype=np.int32)\n",
    "    polyPts = polyPts.reshape((-1, 1, 2))\n",
    "    quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "    # a mask of all corners in quadilateral only\n",
    "    cornerMask = cv2.bitwise_and(cornerMask,cornerMask,mask=quadMask)\n",
    "\n",
    "    return cornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClusterCenters(img, excludedCornerPoints = []):\n",
    "\n",
    "    corner_centers = []\n",
    "\n",
    "    onePixCornerMask = np.zeros(img.shape, dtype='uint8')\n",
    "    # blank_copy = blank.copy()\n",
    "\n",
    "    # create masks\n",
    "    white_mask = cv2.inRange(img, (255,255,255), (255,255,255))\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        if([cx,cy] not in excludedCornerPoints):\n",
    "            onePixCornerMask[cy, cx] = [255, 255, 255]\n",
    "            # cv2.circle(onePixCornerMask, (cx, cy), 1, (255, 255, 255), -1)\n",
    "            corner_centers.append([cx,cy])\n",
    "\n",
    "    onePixCornerMask = cv2.cvtColor(onePixCornerMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return corner_centers, onePixCornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners_w_exclude(img, cornerPoints=[]):\n",
    "    \n",
    "    operatedImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # modify the data type\n",
    "    # setting to 32-bit floating point\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate\n",
    "    # values as input parameters\n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining corners for ray masking\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # for pts in poly_pts:\n",
    "    #     dest[pts[0]][pts[1]] = 0\n",
    "    # Reverting back to the original image,\n",
    "    # with optimal threshold value\n",
    "    size = img.shape\n",
    "\n",
    "    cornerMask = np.zeros(size, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    points,cornerMask = findClusterCenters(cornerMask,cornerPoints)\n",
    "\n",
    "    return cornerMask, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display image \n",
    "img = cv2.imread(imagePath)\n",
    "cv2.imshow(\"img\",img)\n",
    "\n",
    "# right click = view quadilateral (4+)\n",
    "# left click = mounting point (1)\n",
    "cv2.setMouseCallback('img', click_MountingnScale_points)\n",
    "# points are to be selected in the order - \n",
    "# click 1 = nearest edge left point = quadPoints[0]\n",
    "# click 2 = nearest edge right point = quadPoints[1]\n",
    "# click 3 = further edge right point = quadPoints[2]\n",
    "# click 4 = further edge left point = quadPoints[3]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image \n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "# building contours on black image and building mask\n",
    "bldg_brdrs, bldg_mask = getBorderContour_text(img)\n",
    "\n",
    "# gather quadrilateral points\n",
    "polyPts = np.array( quadPoints ,dtype=np.int32)\n",
    "polyPts = polyPts.reshape((-1, 1, 2))\n",
    "\n",
    "# make viewing quadrilateral mask\n",
    "quadMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "# get building borders inside viewing quadrilateral\n",
    "selected_bldg_brdrs = cv2.bitwise_and(bldg_brdrs,bldg_brdrs, mask = quadMask)\n",
    "selected_bldg_brdrs_gray = cv2.cvtColor(selected_bldg_brdrs, cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "# \n",
    "selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "\n",
    "# all_selected_corner = cv2.bitwise_and(bldg_brdrs, quadMask)\n",
    "# all_selected_corner = getCorners(all_selected_corner)\n",
    "\n",
    "# building corners inside viewing quadrilateral\n",
    "original_corners = getCorners(bldg_brdrs, quadPoints)\n",
    "original_corners_g = cv2.cvtColor(original_corners, cv2.COLOR_BGR2GRAY)\n",
    "_, cornerPix = findClusterCenters(original_corners)\n",
    "\n",
    "# Points displayed on img\n",
    "# imgCornerPix = np.add(img, original_corners)\n",
    "\n",
    "cv2.imshow(\"bldg_brdrs\",cornerPix)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use two masks to distinguish points on the side edges vs points on the nearest edge\n",
    "# side_edge_mask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "# side_edge_mask = cv2.line(side_edge_mask, quadPoints[1], quadPoints[2], 255, 2) #plot right edge\n",
    "# side_edge_mask = cv2.line(side_edge_mask, quadPoints[0], quadPoints[3], 255, 2)   #plot left edge\n",
    "\n",
    "# nearest_edge_mask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "# nearest_edge_mask = cv2.line(side_edge_mask, quadPoints[0], quadPoints[1], 255, 2)   #plot nearest edge\n",
    "# nearest_edge_corner = cv2.bitwise_and(all_selected_corner, nearest_edge_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate loop vars\n",
    "quad_outline = np.zeros(bldg_brdrs.shape[:2], dtype='uint8')\n",
    "one_edge_pic = np.zeros(bldg_brdrs.shape, dtype='uint8')\n",
    "\n",
    "#Doing further calculation based on selected_edge_list[0], but in main code loop over all contours\n",
    "for selected_edge_contour in selected_edge_list:\n",
    "\n",
    "    #there is a chance that there are 2 corners caught in one contour. What to do here ? Choose the more inn\n",
    "\n",
    "    # border of viewing quadrilateral\n",
    "    cv2.polylines(quad_outline, [polyPts],True, 255, 1)\n",
    "\n",
    "    # draws only the selected countor of the for loop\n",
    "    cv2.drawContours(one_edge_pic, [selected_edge_contour], -1, (255,255,255), thickness=1)\n",
    "\n",
    "    # nearest_edge_points = cv2.bitwise_and(nearest_edge_points, )\n",
    "\n",
    "    # finding corners on the selected loop contour\n",
    "    highlightedCorner = getCorners(one_edge_pic, quadPoints)\n",
    "    #for all corners in the list (real and generated)\n",
    "    #real corners = actual building corners\n",
    "    #generated corners = building corners generated by viewing quadrilateral cut offs\n",
    "    cornerPoint, highlightedCorner = findClusterCenters(highlightedCorner)\n",
    "\n",
    "    highlightedCorner = cv2.bitwise_and(original_corners_g,highlightedCorner)\n",
    "\n",
    "    # intersection of viewing quadrilateral and selected contour\n",
    "    sample = cv2.bitwise_and(one_edge_pic, one_edge_pic,mask = quad_outline)\n",
    "    cornerCoord, sample = findClusterCenters(sample)\n",
    "\n",
    "    #code in lines to check whether or not there are 2 points detected\n",
    "    #sometimes there can be only 1 or even no points\n",
    "\n",
    "    #initially set these 2 points to invalid coordinates. Fill each of these points depending on the number intersection points returned from \n",
    "    #image manipulations\n",
    "    intersection_pt_1 = [-1,-1]\n",
    "    intersection_pt_2 = [-1,-1]\n",
    "\n",
    "    if(len(cornerCoord)>0):\n",
    "        if(len(cornerCoord)>=1):\n",
    "            intersection_pt_1 = [cornerCoord[0][0],cornerCoord[0][1]]\n",
    "        if(len(cornerCoord)>=2):\n",
    "            intersection_pt_2 = [cornerCoord[1][0],cornerCoord[1][1]]\n",
    "\n",
    "    img_final = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "    mask_1_pts = np.array( [intersection_pt_1, cornerPoint[0], intersection_pt_1_1, slope_intersection_pt] ,dtype=np.int32)\n",
    "    mask_1_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "    mask_1 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "    mask_1 = cv2.fillPoly(mask_1, pts=[mask_1_pts],color = 255)\n",
    "    mask_1_inverted = cv2.bitwise_and(mask_1, quadMask)\n",
    "    mask_1 = cv2.bitwise_not(mask_1_inverted)\n",
    "\n",
    "cv2.imshow(\"selected corner\",highlightedCorner)\n",
    "cv2.imshow(\"selected contour\",one_edge_pic)\n",
    "cv2.imshow(\"selected intersections\",sample)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "16305.0\n",
      "354\n",
      "12517.5\n"
     ]
    }
   ],
   "source": [
    "#for each point, need to decide which farthest edge point constitutes the last point\n",
    "#eqs of side edges of quadrilateral\n",
    "slope_left_edge = (quadPoints[3][1] - quadPoints[0][1])/(quadPoints[3][0] - quadPoints[0][0])\n",
    "slope_right_edge = (quadPoints[2][1] - quadPoints[1][1])/(quadPoints[2][0] - quadPoints[1][0])\n",
    "c_left_edge = quadPoints[3][1] - slope_left_edge*quadPoints[3][0]\n",
    "c_right_edge = quadPoints[1][1] - slope_left_edge*quadPoints[1][0]\n",
    "\n",
    "intersection_pt_1_1 = [-1,-1] #assign the point to the right most point of viewing quad initially, change if the condition below is satisfied\n",
    "intersection_pt_2_2 = [-1,-1] #assign the point to the right most point of viewing quad initially, change if the condition below is satisfied\n",
    "\n",
    "# what if one of the points lies on nearest edge/farthest edge. if both the points lie on the nearest/farthest edge\n",
    "# ideally, for a given building, if one of the building endings lies on the left edge, the corresponding 4th ed \n",
    "\n",
    "if(intersection_pt_1[0]!=-1):   #if intersection_pt_1 has valid info inside it (i.e. if it was found)\n",
    "    print(intersection_pt_1[1])\n",
    "    print(slope_left_edge*intersection_pt_1[0] + c_left_edge)\n",
    "    if(intersection_pt_1[1] == (slope_left_edge*intersection_pt_1[0] + c_left_edge)):   #check if intersection pt 1 lies on left edge\n",
    "        intersection_pt_1_1 = quadPoints[3]\n",
    "    else:\n",
    "        intersection_pt_1_1 = quadPoints[2] #set to right edge point\n",
    "\n",
    "if(intersection_pt_2[0]!=-1):   #if intersection_pt_2 has valid info inside it (i.e. if it was found)\n",
    "    print(intersection_pt_2[1])\n",
    "    print(slope_left_edge*intersection_pt_2[0] + c_left_edge)\n",
    "    if(intersection_pt_2[1] == (slope_left_edge*intersection_pt_2[0] + c_left_edge)):   #check if intersection pt 2 lies on left edge\n",
    "        intersection_pt_2_2 = quadPoints[3]\n",
    "    else:\n",
    "        intersection_pt_2_2 = quadPoints[2] #set to right edge point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487, 357]\n",
      "(493, 357)\n",
      "[412, 354]\n",
      "(493, 357)\n",
      "[488.18912462811346, 356.85059393255005]\n",
      "[(165, 44), (486, 47), (493, 357), (171, 347)]\n"
     ]
    }
   ],
   "source": [
    "mountingPoint = mountingPoints[0]\n",
    "\n",
    "slope_farthest_edge = (quadPoints[3][1]-quadPoints[2][1])/(quadPoints[3][0]-quadPoints[2][0]) #slope of farthest edge line\n",
    "\n",
    "c2 = quadPoints[3][1] - slope_farthest_edge*quadPoints[3][0] #constant of farthest edge line\n",
    "\n",
    "slope = (mountingPoint[1] - cornerPoint[0][1])/(mountingPoint[0] - cornerPoint[0][0])\n",
    "#find the intersection point b/w the farthest edge line and the line joining cornerPoint and mountingPoint\n",
    "#points are selected such that quadPoints[3] and quadPoints[4] represent the points for the farthest edge\n",
    "\n",
    "#finding intersection point of both lines associated w/ slope\n",
    "#x_intercept = (c2-c1)/(m1-m2)\n",
    "#y_intercept = m1*x_intercept + c1\n",
    "\n",
    "c1 = mountingPoint[1] - slope*mountingPoint[0] #constant of line joining mounting point and corner = y1 - mx1\n",
    "\n",
    "#have obtained one point for the blacked out region\n",
    "x_intercept = (c2-c1)/(slope - slope_farthest_edge)\n",
    "y_intercept = slope*x_intercept + c1\n",
    "\n",
    "slope_intersection_pt = [x_intercept, y_intercept]\n",
    "\n",
    "print(intersection_pt_1)\n",
    "print(intersection_pt_1_1)\n",
    "print(intersection_pt_2)\n",
    "print(intersection_pt_2_2)\n",
    "print(slope_intersection_pt)\n",
    "print(quadPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "img_final = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "\n",
    "mask_1_pts = np.array( [intersection_pt_1, cornerPoint[0], intersection_pt_1_1, slope_intersection_pt] ,dtype=np.int32)\n",
    "mask_1_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "mask_1 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "mask_1 = cv2.fillPoly(mask_1, pts=[mask_1_pts],color = 255)\n",
    "mask_1_inverted = cv2.bitwise_and(mask_1, quadMask)\n",
    "mask_1 = cv2.bitwise_not(mask_1_inverted)\n",
    "#~~~~~~~~~#\n",
    "#NOT IMPLEMENTED YET\n",
    "#order of points matters. instead of going direct for the quadrilateral fill, maybe use 2 triangles instead ?\n",
    "mask_2_pts = np.array( [intersection_pt_2, cornerPoint[0], intersection_pt_2_2,slope_intersection_pt] ,dtype=np.int32)\n",
    "mask_2_pts = mask_1_pts.reshape((-1, 1, 2))\n",
    "\n",
    "mask_2 = np.zeros(img_final.shape[:2], dtype='uint8')\n",
    "mask_2 = cv2.fillPoly(mask_2, pts=[mask_2_pts],color = 255)\n",
    "mask_2_inverted = cv2.bitwise_and(mask_2, quadMask)\n",
    "mask_2 = cv2.bitwise_not(mask_2_inverted)\n",
    "#~~~~~~~~#\n",
    "\n",
    "combined_mask = np.add(mask_1_inverted, mask_2_inverted)\n",
    "combined_mask = cv2.bitwise_not(combined_mask)\n",
    "\n",
    "img_final = cv2.bitwise_and(img_final, mask_1)\n",
    "img_final = cv2.bitwise_or(img_final, quad_outline)\n",
    "\n",
    "mask_diff = np.subtract(mask_1, mask_2)\n",
    "\n",
    "cv2.imshow(\"img final\",img_final)\n",
    "cv2.imshow(\"subtract mask 1\",mask_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
