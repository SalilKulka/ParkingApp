{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#NEVER USE NP.ADD always use CV2.BITWISE_OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Images'\n",
    "# Image path\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image\n",
    "\n",
    "theta = (66.75*math.pi)/180    #diagonal angle FOV of camera (GIVEN!!)\n",
    "phi = 2*math.atan(0.8*math.tan(theta/2))  #angle of view larger side of camera resolution (4 in 4:3)\n",
    "omega = 2*math.atan(0.6*math.tan(theta/2))     #angle of view larger side of camera resolution (3 in 4:3)\n",
    "alpha = (75*math.pi)/180   #set later on in the code based on the height of the camera [angle of camera from negative z axis]\n",
    "\n",
    "# read image \n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "mountingPoints = []\n",
    "scalePoints = []\n",
    "quadPoints = [[-1,-1],[-1,-1],[-1,-1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to do test/implement ray masking\n",
    "1. Plot out viewing quadrilateral\n",
    "2. Plot out mounting point\n",
    "3. Mask out for building contours\n",
    "4. Find corners of building contours\n",
    "\n",
    "Taking the nearest corner, find the slope of the line joining the mounting point and this nearest corner. Find the intersection point of this line and the farthest edge of the quadrilateral (What if farthest edge is out of bounds ??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderContour_text(img):\n",
    "#function runs only once\n",
    "#using new bgr values for the new image in low red.\n",
    "\n",
    "    img_c = img.copy()\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "    high_yellow = (242,251,256)\n",
    "\n",
    "    low_gray = (241,241,241)\n",
    "    high_gray = (244,243,241)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(img, low_red, low_red )\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    blank = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    masked = cv2.bitwise_and(img,img,mask=combined_mask)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if(area>200):\n",
    "            for eps in np.linspace(0.001, 0.01, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(blank, [approx], -1, (255,255,255), thickness=1)\n",
    "            # cv2.drawContours(blank, [c], -1, 255, thickness=1)\n",
    "\n",
    "\n",
    "    # cv2.imshow(\"image\",img)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return blank, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mountingPoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners(buildingBorderMask, quadPts, blocksize=3):\n",
    "\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "    # for obtaining corners for ray masking\n",
    "    # ~~~~~~~~~~~~~ #\n",
    "\n",
    "    # Mask may have 3 layers\n",
    "    operatedImage = cv2.cvtColor(buildingBorderMask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) \n",
    "\n",
    "    # modify the data type -- setting to 32-bit floating point\n",
    "    operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method to detect the corners with appropriate values as input parameters\n",
    "    # increase the second parameter ~ blocksize to get more of the corner shape out\n",
    "    dest = cv2.cornerHarris(operatedImage, blocksize, 5, 0.07)  \n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # a mask of all corners of the building contours\n",
    "    cornerMask = np.zeros(buildingBorderMask.shape, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    # Make a gray scale mask of quadilateral area\n",
    "    quadMask = np.zeros(buildingBorderMask.shape[:2], dtype='uint8')\n",
    "    polyPts = np.array( quadPts ,dtype=np.int32)\n",
    "    polyPts = polyPts.reshape((-1, 1, 2))\n",
    "    quadMask = cv2.fillPoly(quadMask, pts=[polyPts],color=255)\n",
    "\n",
    "    # a mask of all corners in quadilateral only\n",
    "    cornerMask = cv2.bitwise_and(cornerMask,cornerMask,mask=quadMask)\n",
    "\n",
    "    return cornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClusterCenters(img, excludedCornerPoints = []):\n",
    "\n",
    "    corner_centers = []\n",
    "\n",
    "    onePixCornerMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "    # blank_copy = blank.copy()\n",
    "\n",
    "    white_mask = np.zeros(img.shape, dtype = 'uint8')\n",
    "\n",
    "    if(len(img.shape)==3):\n",
    "        white_mask = cv2.inRange(img, (255,255,255), (255,255,255))\n",
    "    else:\n",
    "        white_mask = cv2.inRange(img, 255, 255)\n",
    "\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        if([cx,cy] not in excludedCornerPoints):\n",
    "            onePixCornerMask[cy,cx] = 255\n",
    "            # cv2.circle(onePixCornerMask, (cx, cy), 1, (255, 255, 255), -1)\n",
    "            corner_centers.append([cx,cy])\n",
    "\n",
    "\n",
    "    return corner_centers, onePixCornerMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorners_w_exclude(img, cornerPoints=[]):\n",
    "    \n",
    "    operatedImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # modify the data type\n",
    "    # setting to 32-bit floating point\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # operatedImage = np.float32(operatedImage)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate\n",
    "    # values as input parameters\n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining corners for ray masking\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 5, 0.07)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # for pts in poly_pts:\n",
    "    #     dest[pts[0]][pts[1]] = 0\n",
    "    # Reverting back to the original image,\n",
    "    # with optimal threshold value\n",
    "    size = img.shape\n",
    "\n",
    "    cornerMask = np.zeros(size, dtype='uint8')\n",
    "    cornerMask[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    points,cornerMask = findClusterCenters(cornerMask,cornerPoints)\n",
    "\n",
    "    return cornerMask, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointGen(source, m, l):\n",
    "    # m is the slope of line, and the\n",
    "    # required Point lies distance l\n",
    "    # away from the source Point\n",
    "    a = Point(0, 0)\n",
    "    b = Point(0, 0)\n",
    "\n",
    "    # slope is 0\n",
    "    if m == 0:\n",
    "        a.x = source.x + l\n",
    "        a.y = source.y\n",
    "\n",
    "        b.x = source.x - l\n",
    "        b.y = source.y\n",
    "\n",
    "    # if slope is infinite\n",
    "    elif math.isfinite(m) is False:\n",
    "        a.x = source.x\n",
    "        a.y = source.y + l\n",
    "\n",
    "        b.x = source.x\n",
    "        b.y = source.y - l\n",
    "    else:\n",
    "        dx = (l / math.sqrt(1 + (m * m)))\n",
    "        dy = m * dx\n",
    "        a.x = source.x + dx\n",
    "        a.y = source.y + dy\n",
    "        b.x = source.x - dx\n",
    "        b.y = source.y - dy\n",
    "    \n",
    "    return [(int(a.x),int(a.y)),(int(b.x),int(b.y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(slope, point, img):\n",
    "    #draws line segment infinitely from edges of image\n",
    "\n",
    "    returnImage = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "    y_lim,x_lim = returnImage.shape\n",
    "    px,py,qx,qz = [-1,-1,-1,-1] #initialize variables with \n",
    "\n",
    "    if(slope==-1):\n",
    "        px = point[0]\n",
    "        py = y_lim\n",
    "\n",
    "        qx = point[0]\n",
    "        qy = 0\n",
    "    else:\n",
    "        px = x_lim\n",
    "        py = slope*x_lim + (point[1] - slope*point[0])\n",
    "\n",
    "        qx = 0\n",
    "        qy = (point[1] - slope*point[0])\n",
    "        \n",
    "    cv2.line(returnImage, (int(px),int(py)),(int(qx), int(qy)), 255, 1)\n",
    "    return returnImage  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Detect all corners in the image and mask out the view quadrilateral.. to get point only in the interior of the quad\\n\n",
    "##### Step 2: Mask out the view quadrilateral in the original img and then run corner detection.. to get all points interior and on edge\n",
    "##### Step 3: Loop through every line of every contour inside quad\n",
    "##### Step 4: For each line AND it with the interior corner points\n",
    "##### Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "##### Step 6: Get the slope from the mounting point to those interior corners\n",
    "##### Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "##### Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "##### Step 9: OR all the quadrilateral generated inside the loop on the view quad mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COLLECT MOUNTING POINTS\n",
    "\n",
    "# read and display image \n",
    "img = cv2.imread(imagePath)\n",
    "cv2.imshow(\"img\",img)\n",
    "\n",
    "# right click = view quadilateral (4+)\n",
    "# left click = mounting point (1)\n",
    "cv2.setMouseCallback('img', click_MountingnScale_points)\n",
    "# points are to be selected in the order - \n",
    "# click 1 = nearest edge left point = quadPoints[0]\n",
    "# click 2 = nearest edge right point = quadPoints[1]\n",
    "# click 3 = further edge right point = quadPoints[2]\n",
    "# click 4 = further edge left point = quadPoints[3]\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleConst = 20 # for the below pixel distance, this represent\n",
    "scalePoints = [(302, 373), (464, 373)]\n",
    "# Get mounting points from building borders\n",
    "# mountingPoints = get_MP_FromBuildings_ButAlsoText(img)\n",
    "\n",
    "# Pixel distance of scale in image\n",
    "# actual distance(m) = (scale constant)*(obtained magnitude)/scale\n",
    "scale = abs(math.sqrt(pow(scalePoints[0][0] - scalePoints[1][0],2) + pow(scalePoints[0][1] - scalePoints[1][1],2)))\n",
    "\n",
    "# heights = [x*0.1 for x in range(30,60)] #average height of light poles is 9 to 14 feet ~ 4.2m max\n",
    "heights = [h*0.1 for h in range(30, 60)]    #3m to 6m\n",
    "# Converting height in meter array to height in pixel array\n",
    "heightPix = [h*scale/scaleConst for h in heights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  17   23]]\n",
      "\n",
      " [[ 860  770]]\n",
      "\n",
      " [[1143   -8]]]\n"
     ]
    }
   ],
   "source": [
    "# angle of camera from negative of vertical axisS\n",
    "img = cv2.imread(imagePath)\n",
    "alpha = 60\n",
    "ALPHA = alpha*math.pi/180\n",
    "\n",
    "for mountingPoint in mountingPoints:\n",
    "    for beta in range (0,30, 10):\n",
    "\n",
    "        # print(beta)\n",
    "        # beta edge cases\n",
    "        if(beta==180 or beta==0 or beta==360):\n",
    "            continue\n",
    "\n",
    "        # loop vars\n",
    "        BETA = beta*math.pi/180\n",
    "        cameraRoadCoverage = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "\n",
    "        # distances of closer and further edges from mounting point\n",
    "        closer_dist = heightPix[20]*math.tan(ALPHA - (phi/2))\n",
    "        further_dist = heightPix[20]*math.tan(ALPHA + (phi/2))\n",
    "\n",
    "        # slope of horizontal plane camera angle\n",
    "        slope_beta = math.tan(BETA)\n",
    "\n",
    "        # midpoints of closer and further edges\n",
    "        if beta > 180:\n",
    "            closer_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, closer_dist)[1]\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[1]\n",
    "        else:\n",
    "            closer_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, closer_dist)[0]\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[0]\n",
    "\n",
    "        # half of the closer edge length = (heightPix[20]*tan(w/2))/cos(alpha-(phi/2))\n",
    "        # closer_edge = (heightPix[20]*math.tan(omega/2))/math.cos(ALPHA-(phi/2))\n",
    "        # half of the further edge length = (heightPix[20]*tan(w/2))/cos(alpha+(phi/2))\n",
    "        further_edge =(heightPix[20]*math.tan(omega/2))/math.cos(ALPHA+(phi/2))\n",
    "\n",
    "        # Obtaining on ground quadilateral points\n",
    "        # quadPoints[0] = pointGen(Point(closer_midPoint[0],closer_midPoint[1]), -1/slope_beta, closer_edge)[0]\n",
    "        # quadPoints[1] = pointGen(Point(closer_midPoint[0],closer_midPoint[1]), -1/slope_beta, closer_edge)[1]\n",
    "\n",
    "        quadPoints[0] = mountingPoint\n",
    "\n",
    "        quadPoints[1] = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[1]\n",
    "        quadPoints[2] = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[0]\n",
    "\n",
    "# plotting the points\n",
    "pt = np.array(quadPoints, np.int32)\n",
    "pt = pt.reshape((-1,1,2))\n",
    "cameraRoadCoverage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.polylines(cameraRoadCoverage, [pt],True, 255, 1)\n",
    "\n",
    "cutQuadMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cutQuadBorder = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv2.fillPoly(cutQuadMask, [pt], 255)\n",
    "\n",
    "# findcontours\n",
    "cnts=cv2.findContours(cutQuadMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "for c in cnts:\n",
    "    # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "    area = cv2.contourArea(c)\n",
    "    for eps in np.linspace(0.001, 0.01, 10):\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "    \n",
    "    # draw the approximated contour on the image  \n",
    "    cv2.drawContours(cutQuadBorder, [approx], -1, (255,255,255), thickness=1)\n",
    "\n",
    "print(pt)\n",
    "\n",
    "cv2.imshow(\"area covered\", cutQuadBorder)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h, w = img.shape[:2]\n",
    "# imgBrdrPts = np.array([(0,0), (w, 0), (w,h), (0,h)], np.int32)\n",
    "# imgOutlineMask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "# imgBrdrPts = imgBrdrPts.reshape((-1,1,2))\n",
    "# cv2.polylines(imgOutlineMask, [imgBrdrPts],True, 255, 5)\n",
    "# imgOutlineMask = cv2.bitwise_not(imgOutlineMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadMask = cutQuadMask\n",
    "bldg_brdrs, _ = getBorderContour_text(img)\n",
    "\n",
    "# get building borders inside viewing quadrilateral\n",
    "selected_bldg_brdrs = cv2.bitwise_and(bldg_brdrs,bldg_brdrs, mask = quadMask)\n",
    "selected_bldg_brdrs_gray = cv2.cvtColor(selected_bldg_brdrs, cv2.COLOR_BGR2GRAY) # Gray\n",
    "\n",
    "# \n",
    "selected_edge_list = cv2.findContours(selected_bldg_brdrs_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "selected_edge_list = selected_edge_list[0] if len(selected_edge_list) == 2 else selected_edge_list[1]\n",
    "\n",
    "# all_selected_corner = cv2.bitwise_and(bldg_brdrs, quadMask)\n",
    "# all_selected_corner = getCorners(all_selected_corner)\n",
    "\n",
    "# building corners inside viewing quadrilateral\n",
    "original_corners = getCorners(bldg_brdrs, quadPoints)\n",
    "original_corners_g = cv2.cvtColor(original_corners, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Detect all corners in the image and mask out the view quadrilateral.. to get point only in the interior of the quad\n",
    "\n",
    "_, cornerPix = findClusterCenters(original_corners) #cornerPix is all corner on the inside of the view quadrilateral\n",
    "\n",
    "# Points displayed on img\n",
    "# imgCornerPix = np.add(img, original_corners)\n",
    "\n",
    "cv2.imshow(\"bldg_brdrs\",selected_bldg_brdrs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Mask out the view quadrilateral in the original img and then run corner detection.. to get all points interior and on edge\n",
    "\n",
    "# bldg_borders_view_masked = cv2.bitwise_and(bldg_brdrs, bldg_brdrs, mask = quadMask)\n",
    "# all_corners_found = getCorners(bldg_borders_view_masked, quadPoints)\n",
    "# all_corners_found = findClusterCenters(all_corners_found)   #all corners on the interior and on edge\n",
    "\n",
    "# blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "# nearestEdgeMask = cv2.line(blank, quadPoints[0], quadPoints[1], 255, 1)   #plot nearest edge\n",
    "\n",
    "# blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "# farthestEdgeMask = cv2.line(blank, quadPoints[2], quadPoints[3], 255, 1)   #plot farthest edge\n",
    "\n",
    "# # cv2.imshow(\"farthest edge\", farthestEdgeMask)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "# quad_outline = np.zeros(bldg_brdrs.shape[:2], dtype='uint8')\n",
    "# cv2.polylines(quad_outline, [pt],True, 255, 1)\n",
    "# mountingPoint = mountingPoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 25]] [[17, 23]] [372, 410] [300, 413]\n",
      "[] [] [301, 471] [301, 486]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Salil kulkarni\\Desktop\\TARQ\\Parking\\ParkingApp\\RayMasking_Atharva.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m lineMask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(img\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# There is a concern that the points are listed in not the correct order...\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m blockPts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray( [interiorPointCoords_1, interiorPointCoords_2, PointCoords_1[\u001b[39m0\u001b[39;49m], PointCoords_2[\u001b[39m0\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m blockPts \u001b[39m=\u001b[39m blockPts\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Salil%20kulkarni/Desktop/TARQ/Parking/ParkingApp/RayMasking_Atharva.ipynb#X25sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m lineMask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mfillPoly(lineMask, pts\u001b[39m=\u001b[39m[blockPts],color\u001b[39m=\u001b[39m\u001b[39m255\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Step 3: Loop through every line of every contour inside quad\n",
    "# for selected_edge_contour in selected_edge_list:\n",
    "\n",
    "selected_edge_contour = selected_edge_list[0]\n",
    "\n",
    "#mask related to a single contour, to which individual line blocking masks will be OR'ed to \n",
    "totalMask = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "\n",
    "oneContourPic = np.zeros(img.shape, dtype='uint8')\n",
    "cv2.drawContours(oneContourPic, [selected_edge_contour], -1, (255,255,255), thickness=1) #draws only selected contour for the loop\n",
    "oneContourPic = cv2.cvtColor(oneContourPic, cv2.COLOR_BGR2GRAY)   #convert drawn picture into grayscale\n",
    "\n",
    "cv2.imshow(\"one contour\", oneContourPic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "oneContourPic = cv2.Canny(oneContourPic,50,150,apertureSize=3)\n",
    "# cv2.imshow(\"one Contour\", oneContourPic)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Apply HoughLinesP method to \n",
    "# to directly obtain line end points\n",
    "lines = cv2.HoughLinesP(\n",
    "            oneContourPic, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=10, # Min number of votes for valid line. Use lesser number of votes for smaller lines\n",
    "            minLineLength=5, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    "for points in lines:\n",
    "\n",
    "    # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "\n",
    "    # Step 4: For each line AND it with the interior corner points ??\n",
    "\n",
    "    interiorPointCoords_1 = [y1, x1]\n",
    "    interiorPointCoords_2 = [y2, x2]\n",
    "\n",
    "    # Step 5: Isolate the points and their coordinates that intersect with the contour line\n",
    "    # Step 6: Get the slope from the mounting point to those interior corners\n",
    "    # Step 7: Drop a line from the interior corners to edge of image on a quad mask so you dont have to find intersection point with further edge\n",
    "    \n",
    "    joiningLine_1 = drawLine((mountingPoint[1] - interiorPointCoords_1[1])/(mountingPoint[0] - interiorPointCoords_1[0]), interiorPointCoords_1, img)\n",
    "    joiningLine_2 = drawLine((mountingPoint[1] - interiorPointCoords_2[1])/(mountingPoint[0] - interiorPointCoords_2[0]), interiorPointCoords_2, img)\n",
    "    \n",
    "    Point_1 = cv2.bitwise_and(cutQuadBorder, joiningLine_1)\n",
    "    PointCoords_1, t1 = findClusterCenters(Point_1)  #more than one cluster might form or no cluster might wrong\n",
    "\n",
    "    Point_2 = cv2.bitwise_and(cutQuadBorder, joiningLine_2)\n",
    "    PointCoords_2, _ = findClusterCenters(Point_2)  #more than one cluster might form or no cluster might wrong\n",
    "    # farthestEdgePointCoords_1 = [-1,-1]\n",
    "    # farthestEdgePointCoords_2 = [-1,-1]\n",
    "\n",
    "    if(len(Point_1)==0 and len(Point_2)==0):    #i.e. points are not found\n",
    "        PointCoords_1 = PointCoords_1[0]\n",
    "        PointCoords_2 = PointCoords_2[0]\n",
    "\n",
    "# cv2.imshow(\"Farthest Edge Point\", Point_2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "    print(PointCoords_1, PointCoords_2, interiorPointCoords_1, interiorPointCoords_2)\n",
    "\n",
    "    lineMask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "    # Step 8: Fill the quadrilateral made by the line contour, the lines from interior corners or the view quad side wall and the view quad further wall\n",
    "    # There is a concern that the points are listed in not the correct order...\n",
    "    blockPts = np.array( [interiorPointCoords_1, interiorPointCoords_2, PointCoords_1[0], PointCoords_2[0]], dtype=np.int32)\n",
    "    blockPts = blockPts.reshape((-1, 1, 2))\n",
    "    lineMask = cv2.fillPoly(lineMask, pts=[blockPts],color=255)\n",
    "\n",
    "    # Step 9: OR all the quadrilateral generated inside the loop on the view quad mask\n",
    "    totalMask = cv2.bitwise_or(totalMask, lineMask)\n",
    "\n",
    "\n",
    "totalMask = cv2.bitwise_not(totalMask)\n",
    "\n",
    "cv2.imshow(\"Farthest Edge Point\", totalMask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
