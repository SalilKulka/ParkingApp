{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module\n",
    "import cv2\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imagePath = 'Images'\n",
    "imageName = \"sample3.PNG\"\n",
    "imagePath = os.path.join(imagePath,imageName)\n",
    "resizedImageName = imageName + \"_resized\"\n",
    "#road detection works better with images where the scale is smaller per unit pixel \n",
    "#(screen distance = lesser real world distance)\n",
    "#It also works better with a different style of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalePoints = []\n",
    "mountingPoints = []\n",
    "\n",
    "buffer_length = 0   #buffer length before the midpoint from which viewing must begin\n",
    "theta = (66.75*math.pi)/180    #diagonal angle FOV of camera (GIVEN!!)\n",
    "phi = 2*math.atan(0.8*math.tan(theta/2))  #angle of view larger side of camera resolution (4 in 4:3)\n",
    "omega = 2*math.atan(0.6*math.tan(theta/2))     #angle of view larger side of camera resolution (3 in 4:3)\n",
    "alpha = (75*math.pi)/180   #set later on in the code based on the height of the camera [angle of camera from negative z axis]\n",
    "\n",
    "minArea = 1000\n",
    "\n",
    "fp1 =0\n",
    "fp2 =0\n",
    "fp3 =0\n",
    "fp4 =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResizedForDisplayImg(img):\n",
    "    screen_w, screen_h = GetSystemMetrics(0), GetSystemMetrics(1)\n",
    "    #print(\"screen size\",screen_w, screen_h)\n",
    "    h,w,channel_nbr = img.shape\n",
    "    # img get w of screen and adapt h\n",
    "    h = h * (screen_w / w)\n",
    "    w = screen_w\n",
    "    if h > screen_h: #if img h still too big\n",
    "        # img get h of screen and adapt w\n",
    "        w = w * (screen_h / h)\n",
    "        h = screen_h\n",
    "    w, h = w*0.9, h*0.9 # because you don't want it to be that big, right ?\n",
    "    w, h = int(w), int(h) # you need int for the cv2.resize\n",
    "    return cv2.resize(img, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoadsHSV(img):\n",
    "\n",
    "    temp_img = img.copy()\n",
    "    hsv = img.copy()\n",
    "    hsv = cv2.cvtColor(hsv, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower = np.array([255, 0, 0], dtype=\"uint8\")\n",
    "    # upper = np.array([121, 255, 255], dtype=\"uint8\")\n",
    "    mask = cv2.inRange(temp_img, lower, lower)\n",
    "    final = cv2.bitwise_and(temp_img,temp_img,mask=mask)\n",
    "\n",
    "    # cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # for c in cnts:\n",
    "    #     for eps in np.linspace(0.0001, 0.0002, 5):\n",
    "    #         # approximate the contour\n",
    "    #         peri = cv2.arcLength(c, True)\n",
    "    #         approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "    #     cv2.drawContours(temp_img, [approx], -1, (36, 255, 12), 2)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMountingPoints(img):\n",
    "\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # Upper and lower color limit customized for snazzy maps\n",
    "    low_red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    red_mask = cv2.inRange(imageCopy, low_red, low_red)\n",
    "    \n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # convert to grayscale\n",
    "    # operatedImage = cv2.cvtColor(combined_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # operatedImage = cv2.fastNlMeansDenoisingColored(operatedImage,None,10,10,7,21) #uncomment if you feel image is noisy (not needed)\n",
    "    # setting to 32-bit floating point\n",
    "    operatedImage = np.float32(combined_mask)\n",
    "\n",
    "    # apply the cv2.cornerHarris method\n",
    "    # to detect the corners with appropriate values as input parameters\n",
    "    dest = cv2.cornerHarris(operatedImage, 2, 3, 0.04)\n",
    "\n",
    "    # Results are marked through the dilated corners\n",
    "    dest = cv2.dilate(dest, None)\n",
    "\n",
    "    # draw on the output image\n",
    "    imageCopy[dest > 0.01 * dest.max()]=[255, 255, 255]\n",
    "\n",
    "    return imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the corners into one point\n",
    "def cluster2Point(clusterImg, img):\n",
    "\n",
    "    # innitates the the single point corner arrays\n",
    "    Points = []\n",
    "\n",
    "    # blank = np.zeros(img.shape, dtype='uint8')\n",
    "    imageCopy = img.copy()\n",
    "\n",
    "    # create masks for the corner clusters\n",
    "    white_mask = cv2.inRange(clusterImg, (255,255,255), (255,255,255))\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(white_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for i in cnts:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        # print(f\"center - {cx},{cy}\")\n",
    "        Points.append([cx,cy])\n",
    "        imageCopy[cy, cx] = [255, 255, 255]\n",
    "        # cv2.circle(imageCopy, (cx, cy), 1, (255, 255, 255), -1)\n",
    "        # cv2.drawContours(blank, [i], -1, 0, -1)\n",
    "\n",
    "    return Points, imageCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoadsnParkings(img):\n",
    "    \n",
    "    tempImg = img.copy()\n",
    "    # define color ranges\n",
    "    # blue_lower = (250,0,0)\n",
    "    blue = np.array([255, 0, 0], dtype=\"uint8\")\n",
    "\n",
    "    # create masks\n",
    "    blue_mask = cv2.inRange(img, blue, blue)\n",
    "\n",
    "    # combine masks\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    #combined_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\n",
    "    for c in cnts:\n",
    "        # area = cv2.contourArea(c)\n",
    "        # for eps in np.linspace(0.001, 0.005, 5):\n",
    "        #     # approximate the contour\n",
    "        #     peri = cv2.arcLength(c, True)\n",
    "        #     approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "        cv2.drawContours(tempImg, [c], -1, 0, -1)\n",
    "\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    #image = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return blue_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MP_FromBuildings_ButAlsoText(img):\n",
    "\n",
    "    # Upper and lower color limit\n",
    "    # low_yellow = (239,248,253)\n",
    "    # high_yellow = (243,252,255)\n",
    "\n",
    "    # low_gray = (241,241,241)\n",
    "    # high_gray = (244,243,241)\n",
    "\n",
    "    low_red = (55, 55, 255)\n",
    "    high_red = (55, 55, 255)\n",
    "\n",
    "    # create masks\n",
    "    # yellow_mask = cv2.inRange(img, low_yellow, high_yellow )\n",
    "    # gray_mask = cv2.inRange(img, low_gray, high_gray)\n",
    "    red_mask = cv2.inRange(img, low_red, high_red)\n",
    "\n",
    "    # combine masks\n",
    "    # combined_mask = cv2.bitwise_or(yellow_mask, gray_mask)\n",
    "    kernel = np.ones((3,3), dtype=np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE,kernel)\n",
    "\n",
    "    # findcontours\n",
    "    cnts=cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    output = img.copy()\n",
    "    for c in cnts:\n",
    "        # cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 500:\n",
    "            for eps in np.linspace(0.001, 0.008, 10):\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            \n",
    "            # draw the approximated contour on the image  \n",
    "            cv2.drawContours(output, [approx], -1, (0, 255, 0), thickness=1)\n",
    "            #cv2.drawContours(img, [c], -1, (255,0,255), thickness=1)\n",
    "\n",
    "    # write points in mounting list\n",
    "    # mountingPoints = []\n",
    "    # for y in range(len(img)):\n",
    "    #     for x in range(len(img[y])):\n",
    "    #         b = img[y, x, 0]\n",
    "    #         g = img[y, x, 1]\n",
    "    #         r = img[y, x, 2]\n",
    "    #         if(b == 255 and g == 0 and r == 255):\n",
    "    #             mountingPoints.append((x,y))\n",
    "\n",
    "    # return mountingPoints\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointGen(source, m, l):\n",
    "    # m is the slope of line, and the\n",
    "    # required Point lies distance l\n",
    "    # away from the source Point\n",
    "    a = Point(0, 0)\n",
    "    b = Point(0, 0)\n",
    "\n",
    "    # slope is 0\n",
    "    if m == 0:\n",
    "        a.x = source.x + l\n",
    "        a.y = source.y\n",
    "\n",
    "        b.x = source.x - l\n",
    "        b.y = source.y\n",
    "\n",
    "    # if slope is infinite\n",
    "    elif math.isfinite(m) is False:\n",
    "        a.x = source.x\n",
    "        a.y = source.y + l\n",
    "\n",
    "        b.x = source.x\n",
    "        b.y = source.y - l\n",
    "    else:\n",
    "        dx = (l / math.sqrt(1 + (m * m)))\n",
    "        dy = m * dx\n",
    "        a.x = source.x + dx\n",
    "        a.y = source.y + dy\n",
    "        b.x = source.x - dx\n",
    "        b.y = source.y - dy\n",
    "    \n",
    "    return [[a.x,a.y],[b.x,b.y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorner(image):\n",
    "\n",
    "    # making a copy of the image to have the original image untouched in main loop\n",
    "    imageSub = image.copy()\n",
    "\n",
    "    # convert to gray and perform Harris corner detection\n",
    "    gray = cv2.cvtColor(imageSub,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    \n",
    "    #~~~~~~~~~~~~~#\n",
    "    #for obtaining mounting points from red buildings img\n",
    "    #~~~~~~~~~~~~~#\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "\n",
    "    # threshold for an optimal value, it may vary depending on the image.\n",
    "    imageSub[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "    return imageSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_MountingnScale_points(event, x, y, flags, params):\n",
    "\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        scalePoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(x) + ',' +str(y), (x,y), font,1, (255, 255, 0), 2)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "\n",
    "    # checking for right mouse clicks    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        scalePoints.append((x,y))\n",
    "\n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        b = img[y, x, 0]\n",
    "        g = img[y, x, 1]\n",
    "        r = img[y, x, 2]\n",
    "        cv2.putText(img, str(b) + ',' +str(g) + ',' + str(r),(x,y), font, 1,(255, 255, 0), 2)\n",
    "        cv2.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the image\n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "# resizing and reading the resized the image\n",
    "# img_temp = getResizedForDisplayImg(img)\n",
    "# cv2.imwrite(os.path.join(imagePath, resizedImageName+\".PNG\"), img_temp)\n",
    "# img = cv2.imread(imagePath)\n",
    "\n",
    "\n",
    "# displaying the image\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "# setting mouse handler for the image\n",
    "cv2.setMouseCallback('image', click_MountingnScale_points)\n",
    "\n",
    "# exit image window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Scale for pix to meter conversion\n",
    "# scaleConst = int(input('Scale: '))\n",
    "scaleConst = 10\n",
    "\n",
    "# Get mounting points from building borders\n",
    "# mountingPoints = get_MP_FromBuildings_ButAlsoText(img)\n",
    "\n",
    "# Pixel distance of scale in image\n",
    "# actual distance(m) = (scale constant)*(obtained magnitude)/scale\n",
    "scale = abs(pow(pow(scalePoints[0][0] - scalePoints[1][0],2) + pow(scalePoints[0][1] - scalePoints[1][1],2),0.5))\n",
    "\n",
    "# heights = [x*0.1 for x in range(30,60)] #average height of light poles is 9 to 14 feet ~ 4.2m max\n",
    "heights = [h*0.1 for h in range(30, 60)]\n",
    "# Converting height in meter array to height in pixel array\n",
    "heightPix = [h*scale/scaleConst for h in heights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the resized the image\n",
    "img = cv2.imread(imagePath)\n",
    "\n",
    "# obtaining the mask of the roads and parkings in the map image\n",
    "road = getRoadsnParkings(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('win', road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath)\n",
    "\n",
    "mountingCluster = getMountingPoints(img)\n",
    "mountingPointsList, mountingPointsImg = cluster2Point(mountingCluster, img)\n",
    "\n",
    "cv2.imshow(\"mounting points as pixels\", mountingPointsImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle of camera from negative of vertical axisS\n",
    "alpha = 60\n",
    "ALPHA = alpha*math.pi/180\n",
    "\n",
    "for mountingPoint in mountingPointsList:\n",
    "    for beta in range (0,360, 10):\n",
    "\n",
    "        # beta edge cases\n",
    "        if(beta==180 or beta==0 or beta==360):\n",
    "            continue\n",
    "\n",
    "        # loop vars\n",
    "        BETA = beta*math.pi/180\n",
    "        roadCopy = road.copy()\n",
    "        imgCopy = img.copy()\n",
    "\n",
    "        # distances of closer and further edges from mounting point\n",
    "        closer_dist = heightPix[20]*math.tan(ALPHA - (phi/2))\n",
    "        further_dist = heightPix[20]*math.tan(ALPHA + (phi/2))\n",
    "\n",
    "        # slope of horizontal plane camera angle\n",
    "        slope_beta = math.tan(BETA)\n",
    "\n",
    "        # midpoints of closer and further edges\n",
    "        if beta > 180:\n",
    "            closer_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, closer_dist)[1]\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[1]\n",
    "        else:\n",
    "            closer_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, closer_dist)[0]\n",
    "            further_midPoint = pointGen(Point(mountingPoint[0],mountingPoint[1]), slope_beta, further_dist)[0]\n",
    "\n",
    "        # half of the closer edge length = (heightPix[20]*tan(w/2))/cos(alpha-(phi/2))\n",
    "        closer_edge = (heightPix[20]*math.tan(omega/2))/math.cos(ALPHA-(phi/2))\n",
    "        # half of the further edge length = (heightPix[20]*tan(w/2))/cos(alpha+(phi/2))\n",
    "        further_edge =(heightPix[20]*math.tan(omega/2))/math.cos(ALPHA+(phi/2))\n",
    "\n",
    "        # Obtaining on ground quadilateral points\n",
    "        point1 = pointGen(Point(closer_midPoint[0],closer_midPoint[1]), -1/slope_beta, closer_edge)[0]\n",
    "        point2 = pointGen(Point(closer_midPoint[0],closer_midPoint[1]), -1/slope_beta, closer_edge)[1]\n",
    "        point3 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[1]\n",
    "        point4 = pointGen(Point(further_midPoint[0],further_midPoint[1]), -1/slope_beta, further_edge)[0]\n",
    "\n",
    "        # plotting the points\n",
    "        pt = np.array([point1, point2, point3, point4], np.int32)\n",
    "        pt = pt.reshape((-1,1,2))\n",
    "        cv2.fillPoly(imgCopy, [pt], (251,251,251))\n",
    "\n",
    "        # mask the polygon\n",
    "        polyMask = cv2.inRange(imgCopy, (251,251,251), (251,251,251))\n",
    "        subtractedMask = np.subtract(roadCopy, polyMask)\n",
    "\n",
    "        # find the updated are of camera coverage\n",
    "        subtractedContour = cv2.findContours(subtractedMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        subtractedContour = subtractedContour[0] if len(subtractedContour) == 2 else subtractedContour[1]\n",
    "\n",
    "        area_sum = 0\n",
    "        for contour in subtractedContour:\n",
    "            area = cv2.contourArea(contour)\n",
    "            area_sum += area\n",
    "\n",
    "        if area_sum > minArea:\n",
    "            minArea = area_sum\n",
    "            fp1 = point1\n",
    "            fp2 = point2\n",
    "            fp3 = point3\n",
    "            fp4 = point4\n",
    "            mp = mountingPoint\n",
    "\n",
    "# plotting best shape and the mounting point\n",
    "pts = np.array([fp1, fp2, fp3, fp4], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img, [pts], True, (255,255,0))\n",
    "cv2.circle(img, (mp[0], mp[1]), 5, (255,0,0),2)\n",
    "\n",
    "# showing image\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daed58c29187cd5cecb9b4716cbb9e18f275bd5c3df4c979c0bb7cc643de0754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
